# 常见面试题

## Java 基础

### HashMap 在使用的时候需要注意什么地方



### HashMap 扩容全过程



### bigdecimal 使用的时候需要注意什么

https://juejin.cn/post/7044204935948271629

flaot和double处理小数时会出现**精度缺失**，于是就引进了BigDecimal对象处理小数。而BigDecimal是对象，不可以直接使用+、-、*、/等 [算术运算符] 直接对其对象进行数学运算,需要使用BigDecimal对象中的方法进行四则运算。

* 推荐使用字符串为形参传入构造函数，不推荐将浮点数作为形参传入构造函数
  * 参数类型为double的构造方法的结果有一定的**不可预知性**
* BigDecimal基本上每步运算都需要创建新的BigDecimal对象，比float和double更加的损耗性能。当处理比较重要和对精度有要求的数据（金额）时使用BigDecimal。
* 除法(divide)运算的时候，结果**不能整除而有余数时**会报java.lang.ArithmeticException错误
  * 当调用divide(除法)时，为了避免此java.lang.ArithmeticException错误产生，可以调用 **divide(BigDecimal divisor, int scale, RoundingMode roundingMode)** 也就是divide(new BigDecimal(value),保留小数点后几位小数，舍入模式)方法。



### Lambda 怎么用的，Stream 的实现原理

Lambda 是一个语法糖，但不是匿名内部类的语法糖





### 用到了 jdk 8 哪些新特性



### String 面试题

![image-20221012182418364](https://cdn.jsdelivr.net/gh/Miyuki7/image-host/blog-imgimage-20221012182418364.png)

### Java 值传递还是引用传递？

Java是值传递。

* 当传的是基本类型时，传的是值的拷贝，对拷贝变量的修改不影响原变量；
* 当传的是引用类型时，**传的是引用地址的拷贝**，但是拷贝的地址和真实地址指向的都是同一个真实数据，因此可以修改原变量中的值；
* 当传的是String类型时，虽然拷贝的也是引用地址，指向的是同一个数据，但是String的值不能被修改，因此无法修改原变量中的值。



## 计算机网络

### Https 工作原理，有哪些常见的加密算法

HTTP 四次握手

* 数字签名，证书： MD5，SHA
* 对称加密：DES、ARE
* 非对称加密：RSA





### Cookie 和 Session

* Session 比 Cookie 安全， Session 是存储在服务器端的，Cookie 是存储在客户端的
* Cookie 是客户端保存用户信息的一种机制，用来记录用户的一些信息，并随着用户每次请求发送到服务器
* Session 会在一定时间内保存在服务器上，当访问增多，会比较占用服务器的性能。





## JVM

### G1 和 CMS 的 GC 过程说一下，分别适用于什么场景





### 一个数组 int[10] 在 JVM 上内存怎么分配的，多大空间





### CMS + ParNew 算法的对象分配和垃圾回收流程

CMS:

* 初始标记：仅仅标记一下 GC Roots 能直接关联到的对象，速度很快，需要 stop the world
* 并发标记： 进行 GC root tracing 的过程，在整个过程中耗时最长
* 重新标记：为了修正并发标记期间，因用户程序运作而导致标记产生变动的那部分对象的标记，这个阶段的停顿时间一般会比初始标记阶段稍长一些，需要 stop the world
* 并发清除

缺点：

* 垃圾碎片问题
* 重新标记阶段停顿时间比较长
* concurrent mode failure，这个异常发生在 cms 正在回收的时候。 CMS GC 的过程中，业务线程也在运行，年轻代空间满了，执行 ygc 的时候，需要将存活对象放入老年代，而这个时候老年代空间不足，就会报错
* promotion failed： Minor GC 的时候，survivor 空间不足，对象只能放入老年代，而老年代也放不下，多数是因为老年代有足够空间空间，但是碎片较多，找不到一段连续的区域。



### 什么时候触发 full gc

除了直接调用 System.gc 以外，触发 full gc 的情况有四种

* 老年代空间不足（大对象、大数组直接进入老年代，长期存活的对象进入来年代），为了避免这个原因触发 full gc ，应当尽量避免创建大对象大数组
* 未指定老年代和新生代大小，堆伸缩的时候会产生 full gc，所以一定要配置 -Xmx -Xms

* JDK 1.7 以及以前的 永久代空间满

怎么调优

围绕一个点，策略就是尽量把对象在新生代使用回收，减少晋升老年代的几率





Full GC: 收集整个堆，包括 新生代，老年代，永久代(在 JDK 1.8及以后，永久代被移除，换为metaspace 元空间)等所有部分的模式。

Minor GC触发条件：当Eden区满时，触发Minor GC。



### old 区什么时候触发 CMS GC，什么参数，配置大了会怎么样，配置小了会怎么样



### 为什么会产生浮动垃圾

[并发](https://so.csdn.net/so/search?q=并发&spm=1001.2101.3001.7020)清理阶段用户线程还在运行，这段时间就可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。这些垃圾有个专业名词：浮动垃圾。

## IO

### Select/Poll/Epoll 区别

* Select，时间复杂度 O(n)
  * 它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流.我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。
* poll本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，区别在于，基于链表来存储的. **它没有最大连接数的限制**
* **epoll可以理解为event poll**，事件驱动的，epoll会把哪个流发生了怎样的I/O事件通知我们。复杂度降低为 O(1)



### Epoll 的两种触发模式

* 水平触发，level-triggered
  * 默认模式就是水平触发
  * 只要文件描述符关联的读内核缓冲区非空，有数据可以读取，就一直发出可读信号进行通知
  * 只要文件描述符关联的写缓冲区不满，就一直发出写信号进行通知
* 边缘触发， edge-triggered
  * 当文件描述符关联的读缓冲区由空转化为为空的时候，发出可读信号进行通知
  * 当文件描述符关联的写内核缓冲区由满转化为不满的时候，则发出可写信号通知
* 区别就在于，水平触发是只要读缓冲区有数据，就一直触发可读信号，而边缘触发是只在空转化为非空的时候触发一次。水平触发降低程序检索自己关心的就绪文件描述符的效率，而边缘触发，则不会充斥大量不关心的就绪文件描述符







## 消息中间件

### 顺序消息如何实现

#### **Queue**

Queue（队列）是具有两个主要操作的**顺序数据结构**: 一个项目可以在尾部入队(添加)，从头部出队(消费)。队列在消息传递技术领域扮演着重要的角色: 许多消息传递协议和工具都假定发布者和消费者使用队列类存储机制进行通信。

RabbitMQ 中的队列是 FIFO(先进先出)。一些队列特性，即消费者的优先级和重新排队，会影响消费者所观察到的排序。

### **顺序消息实践**

RabbitMQ 中的 queue 是有序的消息集合。消息以 FIFO 方式进行排队和出队列(交付给消费者)。

FIFO 排序不保证优先级（priority）队列和分片队列（sharded queues）。所以，只要配置普通 queue，不要配置优先级队列和分片队列，那么队列中的消息就是顺序消息。

多个相互竞争的消费者（consumers）、消费者优先级（consumer priorites）、消息重新传递（message redeliveries）也会影响排序。所以，如果要顺序消费消息，只能有一个 Consumer。

总结一下，要实现 RabbitMQ 顺序消息，配置一个 Queue 对应一个 Consumer，把需要保证顺序的 message 都发送到这一个 Queue 当中，关闭 `autoack`，`prefetchCount=1`，每次只消费一条信息，处理过后进行手工ack，然后接收下一条 message，只由一个 Consumer 进行处理。



### 消费者重平衡 会有什么问题



### 重复消费

其实重复消费不可怕，可怕的是你没考虑到重复消费之后，**怎么保证幂等性**。关键在于幂等性的问题

其实还是得结合业务来思考

* 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
* 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
* 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

### 消费失败

#### 生产者弄丢了数据

confirm 机制

* 普通 confirm 模式
* 批量 confirm 模式
* 异步 confirm 模式



生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。

此时可以选择用 RabbitMQ 提供的事务功能，就是生产者**发送数据之前**开启 RabbitMQ 事务 `channel.txSelect()` ，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 `channel.txRollback()` ，然后重试发送消息；如果收到了消息，那么可以提交事务 `channel.txCommit()` 。

但是事务的性能太差了

所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。

#### RabbitMQ 弄丢了数据

这个你必须**开启 RabbitMQ 的持久化**，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。



#### 消费者弄丢了数据

RabbitMQ 如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack` ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，不就没有 `ack` 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。





为了保证消息从队列中可靠地到达消费者，RabbitMQ 提供了消息确认机制。消费者在声明队列时，可以指定 **noAck** 参数，当 noAck=false，RabbitMQ 会等待消费者显式发回 ack 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它。

### MQ 挂了怎么办

高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。



RabbitMQ

* 单机模式。

* 普通集群模式（无高可用性），主要是用于提高吞吐量的，让集群中多个结点服务某个 queue 的读写操作

  * 在多台集群上启动多个 RabbitMQ 实例，**我们创建的 queue 只会存在一个 RabbitMQ  实例上**。但是每个实例都同步了 queue 的元数据，也就是说，消费的时候连接到了另外一个实例，那么这个实例会从 queue 所在的实例上拉取数据过来。

* 镜像集群模式（高可用性）

  * 跟普通集群模式不一样的是，在镜像集群模式下，**我们创建的 queue，无论是元数据还是queue的消息都存在于多个实例上**。

  * 我们每次写消息到 queue 的时候，都会自动把消息同步到多个 实例的 queue 上。

  * 在管理控制台，新增镜像集群模式的策略，可以指定要求数据同步到所有结点或者指定数量的结点。

  * 好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。

  * 坏处就是，扩展性变差了，性能开销变大了，每个消息都要同步到所有结点上

    





### MQ 同步信息怎么保证一致性和实时性







## Mysql



### Select *  和 Select b  的区别

* 前者多一步提取表字段的步骤，效率低
* 前者扩展性好，应对频繁调整的表结构，适应力强，代码不需要改变。开发环境中可以尝试使用，一般不会用于生产环境





### 对于索引，你觉得开发中需要注意什么





### Mysql 深度分页怎么解决

一般从数据的 偏移量着手，减少偏移量的定位时间。





我们一般做深度分页的时候， sql语句往往如下：

SELECT * FROM tb_test ORDER BY id DESC LIMIT 10000, 20;

LIMIT 10000 , 20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行。如果是LIMIT 1000000 , 100，需要扫描1000100 行，在一个高并发的应用里，每次查询需要扫描超过100W行，不慢就没天理了。



采用子查询模式,**其原理依赖于覆盖索引**，**当查询的列，均是索引字段时，性能较快**，因为其只用遍历索引本身。我们自己创建的非主键索引，都是非聚集索引，其不包含非索引字段，所以数据结构较小，系统能快速遍历。

```Mysql
##查询语句
select id from product limit 866613, 20
##优化方式一
SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
##优化方式二
SELECT * FROM product a JOIN (select id from product limit 866613, 20) b ON a.ID = b.id
```



SELECT * FROM tb_test where `year` = 2017 and id > XXXX ORDER BY id desc limit 20;



这里有个限制条件，就是我们只能实现页码顺序滚动

如果不得不做深度分页，还有一个代码技巧：

反例（耗时129.570s）

select * from tb_test LIMIT 20000000, 10;

正例（耗时5.114s）

SELECT a.* FROM tb_test a, (select id from tb_test LIMIT 20000000, 10) b where a.id = b.id;










### Mysql 库表上线之前需要做什么工作



### binLog 和 redoLog 区别



### Mysql 表中有一个字段很大会有什么问题

https://www.jianshu.com/p/30f85b8bcccf

1.mysql在操作数据的时候，以page为单位
  不管是更新，插入，删除一行数据，都需要将那行数据所在的page读到内存中，然后在进行操作，这样就存在一个命中率的问题，如果一个page中能够相对的存放足够多的行，那么命中率就会相对高一些，性能就会有提升
 2.innodb的page大小默认为16kb
  innodb存储引擎表为索引组织表，树底层的叶子节点为一双向链表，因此每个页中至少应该有两行记录，这就决定了innodb在存储一行数据的时候不能够超过8k，但事实上应该更小，有一些InnoDB内部数据结构要存储以及预留操作空间，
 3.blob，text大字段
  **innodb只会存放前768字节在数据页中，**而剩余的数据则会存储在溢出段中（发生溢出情况的时候适用），最大768字节的作用是便于创建前缀索引/prefix index，其余更多的内容存储在额外的page里，哪怕只是多了一个字节。因此，所有列长度越短越好

mysql的 io 以page为单位，因此不必要的数据（大字段）也会随着需要操作的数据一同被读取到内存中来，这样带来的问题由于大字段会占用较大的内存（相比其他小字段），使得内存利用率较差，造成更多的随机读取。

https://blog.csdn.net/usagoole/article/details/104704436

解决方法：

**将大字段完全存放在溢出段中，数据段中只存放20个字节，这样就大大的减小了数据页的空间占用，使得一个数据页能够存放更多的数据行，也就提高了内存的命中率**



### 覆盖索引

即从**非主键索引中就能查到的记录**，而不需要查询主键索引中的记录，避免了回表的产生减少了树的搜索次数，显著提升性能。

**覆盖索引避免了回表现象的产生**，从而减少树的搜索次数，显著提升查询性能，所以使用覆盖索引**是性能优化的一种手段**

### B+ 树特性

### B+ 树一般多高，层高怎么计算



### 如果做海外的业务，使用数据库需要注意什么地方？

时区，多语言，多币种





### 慢查询

**查询慢查询数量**

一般来说一个正常运行的MySQL服务器，**每分钟的慢查询在个位数是正常的，偶尔飙升到两位数也不是不能接受**，接近100系统可能就有问题了，但是还能勉强用。这几次出问题慢查询的数量已经到了1000多。

慢查询的数量保存在mysql库里面的slow_log表。

```mysql
SELECT * FROM slow_log where start_time > '2019/05/19 00:00:00'; 
```

**查看当前进行的查询状态**

大家应该都比较常用`show processlist`来查看当前系统中正在执行的查询，其实这些数据也保存在`information_schema`库里面的`processlist`表，因此如果要做条件查询，直接查询这张表更方便。

比如查看当前所有的process

```text
select * from information_schema.processlist 
```

查看当前正在进行的查询并按照已经执行时间倒排

```text
select * from information_schema.processlist where info is not null order by time desc 
```

正常运行的数据库，因为一条查询的执行速度很快，被我们的select抓到的info不是null的查询数量会很少。我们这样负荷很大的库一般也就只能查到几条。**如果一次能查到info非空的查询有几十条，那么也可以认为系统出问题了。**

https://zhuanlan.zhihu.com/p/66275448

## DDD 了解吗









## Redis

### 使用 Redis 需要注意哪些地方







### 如何保证 Redis，DB 一致性

双删策略，为什么要多删除一次

延时的根本目的就是为了让别的线程先把查询到数据库的数据更新到缓存中，再去删除redis缓存的数据

https://blog.csdn.net/xukaiqiang123/article/details/113544712

### Redis 集群工作原理？如何通信？ Moved 和 ASKED 区别



## 服务设计

### 设计一个短链系统





### 设计一个分布式限流器



## 灰度发布上线流程怎么做的





## 设计模式

### 适配器模式和策略模式有什么区别

你为什么选择用策略模式，不使用适配器模式



在适配器模式中引入了一个被称为适配器的包装类，而它所包装的对象称为适配者，也就是被适配的类。

适配器的实现就是把客户类的请求转化为堆适配者的相应接口的调用

也就是说，当客户类调用适配器的方法，在适配器类的内部将调用适配者的方法，而这个过程对用户是透明的。**因此适配器让那些由于接口不兼容而不能交互的类能够一起工作。**

**适配器用于组合接口不兼容，不能交互的类**

**而策略模式是让接口的定义和实现解耦，让用户能自己选择需要的实现**



**策略模式，出现新的算法时，只要增加一个新的实现了抽象策略类的具体策略类就好了**







### 设计模式的开发原则

* 单一职责原则

  * 一个类只负责一个功能领域中的相应职责

* 开闭原则

  * 软件实体对扩展开放，对修改关闭
  * 抽象化是开闭原则的关键

* 里氏代换原则

  * 任何基类可以出现的地方，子类一定可以出现

* 依赖倒转原则

  * 抽象不依赖于细节，细节依赖于抽象

* 合成复用原则

  * 尽量使用对象的组合，而不是继承
  * OOP 静态化语言，侵入性扩展，就不符合合成复用原则

* 迪米特法则

  * 一个软件实体应当尽可能少的与其他实体发生相互作用

* 接口隔离规则

  * 使用多个专门的接口，而不是一个总接口

    

**单开里氏，依赖合成迪米特接口**





## 数据洗刷怎么做的，双写 怎么避免循环写？





## 倒排索引讲一下



## 分布式锁怎么实现阻塞队列





## 本地锁，怎么实现阻塞队列唤醒的





## 多线程

### 多线程并发控制是怎么使用的，有哪些手段



### ThreadLocal 使用场景

在我们平常的SpringWeb项目中，我们通常会把业务分成Controller、Service、Dao等等，也知道注解@Autowired默认使用单例模式。那有没有想过，当不同的请求线程进来后，因为Dao层使用的是单例，那么负责连接数据库的Connection也只有一个了，这时候如果请求的线程都去连接数据库的话，就会造成这个线程不安全的问题，Spring是怎样来解决的呢？

在 Dao 层里装配的Connection线程肯定是安全的，解决方案就是使用ThreadLocal 方法。当每一个请求线程使用Connection的时候，都会从ThreadLocal 获取一次，如果值为null，那就说明没有对数据库进行连接，连接后就会存入到 ThreadLocal 里，这样一来，每一个线程都保存有一份属于自己的Connection。每一线程维护自己的数据，达到线程的隔离效果。



### **ThreadLocal慎用的场景**

第一点（线程池里线程调用ThreadLocal）：因为线程池里对线程的管理都是线程复用的方法，所以在线程池里线程非常难结束，更有可能的是永远不会结束。这就意味着线程的持续时间是不可估测的，甚至会与JVM的生命周期一致。

第二点（在异步程序里）：ThreadLocal的参数传递是不可靠的，因为线程将请求发送后，不会在等待远程返回结果就继续向下运行了，真正的返回结果得到以后，可能是其它的线程在处理。

第三点：在使用完ThreadLocal，推荐要调用一下remove（）方法，这样会防止内存溢出这种情况的发生，因为ThreadLocal为弱引用。如果ThreadLocal在没有被外部强引用的情况下，在垃圾回收的时候是会被清理掉的，如果是强引用那就不会被清理。



### 在线程池中使用 ThreadLocal 为什么可能导致内存泄露呢？

在线程池中线程的存活时间太长，往往都是和程序同生共死的，这样 Thread 持有的 ThreadLocalMap 一直都不会被回收，再加上 ThreadLocalMap 中的 Entry 对 ThreadLocal 是弱引用（WeakReference），所以只要 ThreadLocal 结束了自己的生命周期是可以被回收掉的。
Entry 中的 Value 是被 Entry 强引用的，即便 value 的生命周期结束了，value 也是无法被回收的，导致内存泄露。

### Syn 锁，ReentrantLock 怎么选择的，选择的原则



### JUC 线程池，线程池参数以及提交任务后怎么执行



### Lock 加锁和解锁过程，公平锁非公平锁实现原理









### Sleep 与 Wait 区别

* 对于 sleep 方法，我们首先要知道，**该方法是属于 Thread 类中的。而 wait 方法是属于 Object 类中的**
* sleep 方法导致了程序暂停执行指定时间，让出 cpu 给其他线程，但是他的监控状态一直保持着，当指定的时间到了又会自动回复运行状态
* **在调用 sleep 方法的过程中，线程不会释放对象锁**
* **而调用 wait 方法的时候，线程会放弃对象锁，而后阻塞，只有调用 notify 方法后才能重新准备获取锁**
* sleep 用 Thread 调用，在非同步状态下就可以调用，而 wait 用**同步监视器**调用，在线程同步的时候调用



### Condition 类 和 Object 类 锁的区别

* Condition 类的 await 方法和 Obejct 类的 wait 方法等效
* signal 方法和 notify 方法等效
* signalAll 方法和 notifyAll 等效
* ReentrtantLock 类可以唤醒指定条件的线程，而 Object 的唤醒是随机的





## Zookeeper

### Zookeeper 如何实现 CP





### Zookeeper 选举的过程，如何投票的





### Zookeeper 作为注册中心有什么问题？海量服务同时重启会出现什么问题

zookeeper 是一个非常优秀的项目，非常成熟，被大量的团队使用，但对于服务发现来讲，zookeeper 真的是一个错误的方案。

在 CAP 模型中，zookeeper 是 CP，意味着面对网络分区时，为了保持一致性，他是不可用的。

因为 zookeeper 是一个分布式协调系统，如果使用最终一致性（AP）的话，将是一个糟糕的设计，他的核心算法是 Zab，所有设计都是为了一致性。

**对于协调系统，这是非常正确的，但是对于服务发现，可用性是第一位的，例如发生了短暂的网络分区时，即使拿到的信息是有瑕疵的、旧的，也好过完全不可用。**



**zookeeper 的性能不适合注册中心**

在大规模服务集群场景中，zookeeper 的性能也是瓶颈。

zookeeper 所有的写操作都是 leader 处理的，在大规模服务注册写请求时，压力巨大，而且 leader 是单点，无法水平扩展。

还有所有服务于 zookeeper 的长连接也是很重的负担。

zookeeper 对每一个写请求，都会写一个事务日志，同时会定期将内存数据镜像dump到磁盘，保持数据一致性和持久性。

这个动作会降低性能，而且对于注册中心来讲，是不需要的。



---

> 上面的文章分析是有问题的
>
> 虽然 ZK 是以 PC 闻名的，如果 Leader 挂了，在重新选举这段时间服务将变得不可用，但是客户端有自己的缓存，注册中心挂了也影响不大。况且，官方测试，重新选举 Leader 的时间不会超过 200ms。因此，这一点上来说，影响确实不是很大
>
> 唯一存在影响的就是，因为只有 Leader 一个结点才可以写，当我们新服务大面积发布的时候，有可能导致高并发流量打到 Leader 上导致宕机。这是真正存在的问题
>
> 解决这个问题两个思路，批量发布，或者使用消息队列，削峰



Dubbo主要包含四种注册中心的实现，分别是ZooKeeper、Redis、Simple以及Multicast 0，但是dubbo的注册中心，目前最多用得确实是ZK。

ZooKeeper是官方推荐的注册中心，稳定性受到肯定，具体的实现在Dubbo源码的dubbo-registry-zookeeper模块中。

Zookeeper本身不是为了服务发现而生，它是一个基于ZAB协议实现的可靠的分布式协调系统，它是强一致（CP）、使用基于TCP的私有协议通信。在应对大规模分布式集群上，Zookeeper的实力都是不容小觑的。

而Redis注册中心，并没有经过长时间运行的可靠性验证，其稳定性依赖于Redis本身。

Simple注册中心是一个简单的基于内存的注册中心实现，它本身就是一个标准的RPC服务，不支持集群，也可能出现单点故障。

Multicast模式则不需要启动任何注册中心，只要通过广播地址，就可以互相发现。服务提供者启动时，会广播自己的地址。消费者启动时，会广播订阅请求，服务提供者收到订阅请求，会根据配置广播或单播给订阅者。不建议在生产环境使用。





## Spring

### 事务注解 transaction 实现原理





### Mybatis 的接口和 mapper 怎么对应执行





### @Configuration 注解的作用 与 @Component 的区别

`@Configuration`注解可以加在类上，让这个类的功能等同于一个bean xml配置文件，可以在这个类中管理创建Bean。

* @Configuration 的注解作用主要是给我们的类添加了 cglib 代理。`proxyBeanMethods = true` 在执行我们的配置类方法时，会执行 cglib 代理类中的方法。
* 有时候处于性能考虑，会设置这个参数为 false，但是后果就是每次调用 @Bean 注解的方法都会创建一个新的 Bean 实例。
* 如果使用 @Component 注解的话，会发现返回的对象和我们从 beanFactory 中获取的不同

