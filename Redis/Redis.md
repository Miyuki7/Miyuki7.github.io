# Redis

https://juejin.cn/post/6844904127055527950

https://juejin.cn/post/6844904127055527950#heading-39

## Redis 数据结构

https://mp.weixin.qq.com/s?__biz=MzU2MDU3MzE1Mg==&mid=2247485141&idx=1&sn=b0d0cd5397e4f4f4f814e68bc26644f9&chksm=fc04b95acb73304c4b994f942580ce7246fd0caddd301b858b131dbcc23ace62cfa8fad029f3&scene=21#wechat_redirect



https://mp.weixin.qq.com/s?__biz=MzU2MDU3MzE1Mg==&mid=2247485153&idx=1&sn=ba9076f7eceec08509aaf9cca5a09eb3&chksm=fc04b96ecb7330786083d0397942762118476cf89ce17f8346350f21833aa3e285a916c2b9ca&scene=21#wechat_redirect

* 字符串
* 列表
* 字典
* 集合
* 有序集合
* bitmap







## 说一下你在项目中的 redis 的应用场景

* 5 大 Value 类型
  * string，list，hash，set，zset

* 基本上就是缓存
* 为的就是 服务无状态，延申思考，看你的项目有哪些数据结构或对象，在单机里需要单机锁，在多机需要分布式锁，抽出来放入 redis
* 无锁化

## Tps/Qps

**QPS**

QPS即每秒查询率，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。



**TPS**

Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均TPS）



redis， 4W - 5W。和 value 的体积大小、类型相关





## Redis 为什么快

* Redis 是基于内存的，绝大部分请求都是纯粹的内存操作。
* 数据结构以及底层编码方式，Redis 的数据结构是专门进行设计的，数据结构简单，对数据操作也简单。
* 采用单线程 + IO 多路复用的模型。
  * 单线程避免了不必要的上下文切换和锁竞争
  * IO 多路复用模型，非阻塞 IO。
* 底层模型不同，它们之间底层实现方式以及客户端之间的通信的应用协议不一样，redis 直接自己构建了 VM 机制。因为一般的系统调用，会浪费一定的时间去移动和请求（基本不用，享受纯内存操作）
* **计算向数据移动**，与 memcache 对比。（在 IO 上优化）
  * 移动数据成本大，移动计算成本小




## Redis 的 vm 机制

 Redis处理的速度很快，因为它是基于[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)的。在内存能够足够容纳数据的时候，所有的数据都存放在内存。这个时候不论是读取数据还是写入数据都是非常快的。但是如果数据量很大，大到内存已经无法全部容纳的时候，这个时候redis是怎么处理的呢？处理速度是否会直线下降?

答案是否定的。Redis使用到了VM, 在redis.conf设置vm-enabled yes 即开启VM功能。

通过VM功能可以实现`冷热数据分离`。使热数据仍在内存中，冷数据保存到磁盘。

这样就可以避免因为内存不足而造成访问速度下降的问题。在这里，需要特别提到的是，Redis并没有使用OS提供的Swap，而是自己实现。

---



1：**OS是基于page(4K)来做的，它的粒度对于Redis来说太大。**而redis的大多数对象都远小于4k，所以一个 OS 页面上可能有多个 redis 对象。另外 redis 的集合对象类型如 list , set 可能存在与多个 OS 页面上。最终可能造成只有10%的key被经常访问，但是所有OS页面都会被OS认为是活跃的，这样只有内存真正耗尽时OS才会交换页面。

2：相比于OS的交换方式。**redis可以将被交换到磁盘的对象进行压缩,保存到磁盘的对象可以去除指针和对象元数据信息。**一般压缩后对象会比内存中对象小10倍。这样redis的vm会比OS vm能少做很多io操作。

3：**OS交换的时候，是会阻塞线程的**，而Redis可以设置让工作线程来完成，主线程仍可以继续接收client的请求。

## Set 、 Zet 分别用于哪些场景

Set：

* 微博,B站等社交网站中有共同关注，共同好友
* 计算差集 并集 交集

 Zet：

- 排行榜应用的实现，取TOP N的实现



## Redis v.s. memcached

> 计算向数据移动，而非数据向计算移动

* **同样都是 key，value 的形式保存数据。**
  * memcached 的 value 只能是 String，Redis 的 value 支持多类型（五大数据类型）
  * 从而引申出 “计算向数据移动，而非数据向计算移动” 的概念，移动数据的成本大于移动计算
  * 因为 memcached 的 value 只能是 String，所以在客户端和服务器端数据交互的时候涉及到序列化和反序列话，需要做**全量 IO**。比如需要 list 特定索引的元素，需要将整个 list 取出来进行反序列化，之后使用索引获取元素。
  * 但是在 redis 中，计算向数据移动，因为 redis 中的 value 支持多类型，有本地方法，可以直接取出指定索引的元素再进行 IO。
  * 此外，Memcached 不支持枚举、持久化和复制
* **网络 IO 模型方面**
  * memcached 是多线程，分为监听线程、worker 线程，引入锁，带来了性能损耗
  * redis 采用单线程 + IO 多路复用，将速度优势发挥到最大
* **内存空间和数据量大小：**
  * MemCached可以修改最大内存，采用LRU算法。
  * Redis增加了VM的特性，突破了物理内存的限制。



## Redis 是单线程还是多线程

* 无论什么版本，**工作线程就是一个**
* 6.x 高版本出现了 IO 多线程

单线程，满足 redis 的串行原子，只不过 IO 多线程后，把 输入/输出 放到更多的线程里去并行

* 执行时间缩短，更快
* 更好地压榨系统及硬件地资源（网卡能够高效的使用）



**充分利用多核，提高网络吞吐**

---



### Redis 线程模型

Redis 基于 Reactor模式来设计开发了自己的一套高效的事**件处理模型**，这套事件处理模型对应的是 Redis 中的**文件事件处理器**。由于文件事件处理器是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

 既然是单线程，如何监听大量的客户端连接呢？

**Redis 通过 IO 多路复用程序来监听来自客户端的大量连接**，它会将感兴趣的事件以及类型注册到内核中并监听每个事件是否发生

**<u>IO 多路复用技术的使用让 Redis 不需要创建额外的线程来监听客户端的大量连接，降低了资源的消耗。（类似 NIO 中的 Selector）</u>**

另外，Redis 服务器是一个事件驱动程序，服务器需要处理两类事件：

* 文件事件： Redis 服务器和客户端之间的网络 IO
* 时间时间： Redis 服务器中的一些操作需要在给定的时间点执行，而时间事件就是处理这类定时操作的

> Redis 基于 Reactor 模式开发了自己的<u>网络事件处理器</u>：这个处理器被称为<u>文件事件处理器</u>（file event handler）。<u>文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器</u>。
>
> 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
>
> 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

文件事件处理器主要包括四个部分：

* 多个 socket （客户端连接）
* IO 多路复用程序 （ 支持多个客户端连接 ）
* 文件事件分派器 （将 socket 关联到相应的事件处理器）
* 事件处理器 （连接应答处理器、命令请求处理器、命令回复处理器      ）    -> 接受连接、处理请求、回复结果

> Redis 作为一个内存服务器，它需要处理很多来自外部的网络请求，它使用 I/O 多路复用机制同时监听多个文件描述符的可读和可写状态，一旦收到网络请求就会在内存中快速处理，由于绝大多数的操作都是纯内存的，所以处理的速度会非常地快。
>
> 在 [Redis 4.0](https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES) 之后的版本，情况就有了一些变动，新版的 Redis 服务在执行一些命令时就会使用『主处理线程』之外的其他线程，例如 `UNLINK`、`FLUSHALL ASYNC`、`FLUSHDB ASYNC` 等非阻塞的删除操作。

- 为什么 Redis 服务使用单线程模型处理绝大多数的网络请求？
- 为什么 Redis 服务增加了多个非阻塞的删除操作，例如：`UNLINK`、`FLUSHALL ASYNC` 和 `FLUSHDB ASYNC`？



### Redis 6.0 之前为什么不使用多线程

> Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。

**“不要为了技术而技术”** 

**<u>Redis 的性能瓶颈不在于 CPU，主要在于内存和网络</u>**



虽然说 Redis 是单线程模型，但是，实际上，**Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。**

不过，Redis 4.0 增加的多线程主要是针对一些<u>大键值对的删除操作的命令</u>，使用这些命令就会使用主线程之外的其他线程来“异步处理”。

**那 Redis6.0 之前为什么不使用多线程？** 我觉得主要原因有 3 点：

* 单线程编程实现简单并且容易维护，方便开发和调试。并且使用单线程 + 文件事件处理器 也能并发的处理客户端的请求。
  * Redis 虽然使用单线程模型处理用户的请求，但是它却**使用 I/O 多路复用机制****并发**处理来自客户端的多个连接，同时等待多个连接发送的请求。
  * 在 I/O 多路复用模型中，最重要的函数调用就是 `select` 以及类似函数，该方法的能够同时监控多个文件描述符（也就是客户端的连接）的可读可写情况，当其中的某些文件描述符可读或者可写时，`select` 方法就会返回可读以及可写的文件描述符个数。
* Redis 并不是 CPU 密集型的服务，Redis 的性能瓶颈不在于 CPU，主要在于内存和网络 （决定性因素）
  * 如果吞吐量不能满足我们的需求，更推荐的做法是使用**分片的方式将不同的请求交给不同的 Redis 服务器来处理**，而不是在同一个 Redis 服务中引入大量的多线程操作。
* 多线程会存在死锁、上下文切换等问题，甚至会影响性能

> Redis 并不是 CPU 密集型的服务，如果不开启 AOF 备份，所有 Redis 的操作都会在内存中完成不会涉及任何的 I/O 操作，这些数据的读写由于只发生在内存中，所以处理速度是非常快的；整个服务的瓶颈在于网络传输带来的延迟和等待客户端的数据传输，也就是网络 I/O，所以使用多线程模型处理全部的外部请求可能不是一个好的方案。



### Redis 6.0 之后为什么引入了多线程

> Redis 在最新的几个版本中加入了一些可以被其他线程异步处理的删除操作，也就是我们在上面提到的 `UNLINK`、`FLUSHALL ASYNC` 和 `FLUSHDB ASYNC`，我们为什么会需要这些删除操作，而它们为什么需要通过多线程的方式异步处理？
>
> #### 删除操作
>
> 我们可以在 Redis 在中使用 `DEL` 命令来删除一个键对应的值，如果待删除的键值对占用了较小的内存空间，那么哪怕是**同步地**删除这些键值对也不会消耗太多的时间。
>
> <u>但是对于 Redis 中的一些超大键值对</u>，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，<u>Redis 可能会需要在释放内存空间上消耗较多的时间</u>，这些操作就会阻塞待处理的任务，<u>影响 Redis 服务处理请求的 可用性</u>。
>
> 然而释放内存空间的工作其实可以由后台线程异步进行处理，这也就是 `UNLINK` 命令的实现原理，<u>它只会将键从元数据中删除，真正的删除操作会在后台异步执行</u>。

Redis 6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈。

虽然 Redis 中引入了多线程，但是 **Redis 的多线程只是把网络 IO 这类耗时的操作放到多线程中执行**，<u>充分利用多核，提高网络吞吐</u>，<u>更好地压榨系统及硬件地资源（网卡能够高效的使用）</u>。

执行命令仍然是单线程顺序执行，不需要担心线程安全问题。

**redis 可以保障内部串行**，外界使用的时候，业务上要自行保障顺序

![image-20220825200917769](C:\Users\Fannsy\AppData\Roaming\Typora\typora-user-images\image-20220825200917769.png)



---

![image-20220825202843910](https://s2.loli.net/2022/08/25/Hn7sS2yJfUEeKdm.png)

**该设计有如下特点：**

1、IO 线程要么同时在读 socket，要么同时在写，不会同时读或写

2、IO 线程只负责读写 socket 解析命令，不负责命令处理





## IO 多路复用如何理解

**多路指的是多个socket连接，复用指的是复用一个线程。**

多路复用主要有三种技术：select，poll，epoll。<u>epoll是最新的也是目前最好的多路复用技术。</u>

采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。



## Redis 存在线程安全的问题吗，为什么？

* 无论什么版本，工作线程就是一个
* 6.x 高版本出现了 IO 多线程

**redis 可以保障内部串行**，外界使用的时候，业务上要自行保障顺序





## Redis 事件机制

http://remcarpediem.net/article/1aa2da89/

Redis中的事件驱动库**只关注网络IO，以及定时器**。该事件库处理下面两类事件：

- 文件事件(file event)：用于处理 Redis 服务器和客户端之间的网络IO。
- 时间事件(time eveat)：Redis 服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是处理这类定时操作的。



Redis基于Reactor模式开发了自己的网络事件处理器，也就是文件事件处理器。文件事件处理器使用IO多路复用技术，同时监听多个套接字，并为套接字关联不同的事件处理函数。当套接字的可读或者可写事件触发时，就会调用相应的事件处理函数。

Redis 使用的IO多路复用技术主要有：`select`、`epoll`、`evport`和`kqueue`等。每个IO多路复用函数库在 Redis 源码中都对应一个单独的文件，比如ae_select.c，ae_epoll.c， ae_kqueue.c等。Redis 会根据不同的操作系统，按照不同的优先级选择多路复用技术。事件响应框架一般都采用该架构，比如 netty 和 libevent。

文件事件是对套接字操作的抽象，每当一个套接字准备好执行 accept、read、write和 close 等操作时，就会产生一个文件事件。因为 Redis 通常会连接多个套接字，所以多个文件事件有可能并发的出现。



I/O多路复用程序负责监听多个套接字，并向文件事件派发器传递那些产生了事件的套接字。



## 缓存穿透

查询没有的 key



## 缓存击穿

热点 key 过期 或者 从来没有被缓存的

数据库有 + 大量并发 + redis 没有缓存



1. 请求 redis ， 肯定没有
2. 大家抢锁，
   1. 抢到了去数据库 O(1)
   2. 没抢上的，睡眠
3. 碰数据库的 ，更新 redisO(1)
4. 唤醒睡眠线程，回到第一步，就有了



## 缓存雪崩

缓存击穿是缓存雪崩的子集

key 的数量是 N 过期 （没有被缓存的）

大量的并发

redis 没有缓存



这些锁必须由一个 redis 提供，key 特别多 AKF 分治



以上问题，核心就是避免 DB 无效/重复 请求



## Redis 是怎么删除过期 key 的

## 缓存是如何回收的



* 后台在轮询，分段，分批的删除过期 key （主动）
* 当访问一个 key 的时候，判断该 key 是否已经过期，过期就清除 （被动）
  * 可以最大化节省 cpu 资源，却对内存非常不友好。极端情况下可能出现大量的过期 key 没有被访问，从而不会被清除


尽量的把内存无用空间**回收**回来





## 缓存是如何淘汰的

* 内存空间不足的情况下会发生淘汰
* 淘汰机制里有不允许淘汰
* lru / lfu / random / TTL
* 全空间
* 设置过 过期的 key 集合中



## 如何进行缓存预热

预热击穿，从而可以联系到上面



* 提前把数据塞入 redis， 你知道哪些是热数据吗？会造成上线很多数据，但是缓存并没有命中，预热击穿
* 除了要预备数据之外，在开发逻辑上也要规避差集，会造成击穿、穿透、雪崩。实施前面介绍的锁方案
* 一劳永逸，未来也不怕了



## 数据库与缓存不一致如何解决

* 恶心点的，可以使用分布式事务解决，意义不大。顶多在 读多 写稀有 的情况下
* redis 是缓存，更倾向于稍微的有时差
* 还是减少 DB 的操作
* 真的要落地， canal

---

canal，译意为水道/管道/沟渠，主要用途是基于 **MySQL 数据库增量日志解析**，提供**增量数据订阅和消费**。

这里我们可以简单地把canal理解为一个用来**同步增量数据的一个工具**。

canal的工作原理就是**把自己伪装成MySQL slave，模拟MySQL slave的交互协议向MySQL Mater发送 dump协议，MySQL mater收到canal发送过来的dump请求，开始推送binary log给canal，然后canal解析binary log，再发送到存储目的地**，比如MySQL，Kafka，Elastic Search等等。

**通过Canal监听数据库变更，并实时消费变更数据，并更新缓存。**



## 简述一下主从不一致的问题

* redis 的确默认是弱一致性，主从是异步的同步
* 锁不能用主从（单实例/分片集群/redlock）  ==》 redssion
* 在配置中提供了必须有多少个 client 连接能同步，可以配置同步因子，趋向于强一致性
* wait 命令 / wait 2 5000





![image-20220822185414908](https://s2.loli.net/2022/08/22/7mYRS4ocJ2G3lVg.png)

## 描述 redis 持久化原理

当前线程阻塞服务，不聊

异步后台进程完成持久化

*  fork + copyonwrite



## 描述 redis 持久化方式

1. 持久化两个（2 + 1）方案 ： RDB + AOF (主从同步也算持久化)
2. 高版本当中，开启 AOF ， AOF 是可以通过执行日志得到全部内存数据的方式，不需要 RDB了。但是追求性能
   1. 体积变大，重复无用，可抵消，重写，后台用线程把内存的 kv 生成指令写个新的 aof
   2. 4.x 新增性能模式，把重写的方式换成直接 RDB放到 AOF 头部，比 1 方法更快，再追加日志

RDB 优点：全量数据快照，文件小，恢复快。

RDB 缺点：无法保存最近一次快照之后的数据。

AOF 优点：可读性高，适合保存增量数据，数据不易丢失。

AOF 缺点：文件体积大，恢复时间长



> AOF 文件比 RDB 更新频率高，优先使用 AOF 还原数据

### RDB

在指定的时间间隔内将内存中的数据快照写入磁盘，实际操作过程是 copyOnRight。先 fork 一个子进程，将数据集写入临时文件，写入成功后，再替换之前的文件，二进制压缩存储。

优点：

* 全量数据快照，文件小，恢复快。

缺点：

* 无法保存最近一次快照之后的数据。

---

Redis 提供了两个命令来生成 RDB 快照文件：



1. **save** : 主线程执行，**会阻塞主线程；**
2. **bgsave** : 子线程执行，**不会阻塞主线程**，默认选项。

### AOF

以日志的形式记录服务器所处理的每一个写、删除操作。以文本的方式记录

* 优点：可读性高，适合保存增量数据，数据不易丢失
  * RDB 的数据安全性不如 AOF，**没有办法实时或者秒级持久化数据**。
  * AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。

* 缺点：
  * AOF 文件比 RDB 文件大，恢复速度慢
  * 数据集大的时候，比 RDB 启动效率低





## Redis 实现分布式锁的指令

## 为什么使用 setnx

* 好东西，原子（不存在的情况下完成创建）
* 如果要做分布式锁，就要用 set k v nx ex （不存在，过期时间，避免死锁）

> 不存在，过期时间，避免死锁

* 首先利用 set k v nx ex，如果 key 不存在才能获取到锁，如果 key 存在，就获取不到锁
* 然后还要利用 lua 脚本来保证多个 redis 操作的原子性
* 同时还要考虑锁过期，需要一个额外的看门狗定时任务来监听锁是否需要续约
* 同时还要考虑到 redis 节点挂掉以后的情况。需要采用红锁的方式同时向 N/2 + 1 个节点申请锁，都申请到了才能证明成功获取锁，这样就算其中某个 redis 节点挂掉了，锁也不能被其他客户端获取到

> 红锁采用主节点过半机制，即获取锁或者释放锁成功的标志为：在过半的节点上操作成功。



## Redis 内存碎片

* 产生原因
  * Redis 存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间
  * 频繁修改 Redis 中的数据，redis 通常不会轻易释放内存给操作系统，会生成内存碎片
  * 删除 bigKey之后，会产生大量内存碎片，涉及到操作系统的碎片整理也会比较耗时。
  * 可以通过修改配置文件，避免内存碎片率过大







## Watch Dog

如果拿到分布式锁的节点宕机，且这个锁正好处于锁住的状态，会出现锁死的状态。为了避免这种情况的发生，锁都会设置一个过期时间。

但是这样也存在一个问题，假如一个线程拿到了锁并且设置 30 秒超时，在 30 秒后这个线程还没有执行完毕，锁超时释放了，就会导致问题。

因此引入了 watch dog 看门狗机制用于监控锁

在 redisson 实例被关闭前，不断延长锁的有效期。也就是说如果一个拿到锁的线程一直没有完成逻辑，那么看门狗会帮助线程不断的延长锁超时时间，锁不会因超时而释放。

默认情况下，看门狗的续期时间是 30s



## 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？

- 使用keys指令可以扫出指定模式的key列表。
- 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？
   这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

## Redis 集群方案

> 主从复制模式能实现读写分离，但是不能自动故障转移；
>
> 哨兵模式基于主从复制模式，能实现自动故障转移，达到高可用，但与主从复制模式一样，不能在线扩容，容量受限于单机的配置；
>
> Cluster模式通过无中心化架构，实现分布式存储，可进行线性扩展，也能高可用，但对于像批量操作、事务操作等的支持性不够好。

### 主从模式

客户端可对主数据库进行读写操作，对从数据库进行读操作，主数据库写入的数据会实时自动同步给从数据库。

优点：

1.  master能自动将数据同步到slave，可以进行读写分离，分担master的读压力
2.  master、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求

缺点：

master宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题



### 哨兵模式

sentinel 主要有以下功能：

* 集群监控： 负责监控 redis master 和 slave 进程是否正常工作
* 消息通知： 如果某个 redis 实例有故障，哨兵负责发送消息作为报警通知给管理员
* 故障转移： 如果 master 挂掉了，会自动选举 某个 slave 作为新的 master
* 配置中心： 如果故障转移发生了，通知客户端新的 master 地址

哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作

* 故障转移时，判断一个 master 是否挂掉了，需要大部分哨兵同意
* 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作
* 哨兵 + redis 主从部署，不能保证数据零丢失，只能保证 redis 集群的高可用 



### 集群模式 Cluster

redis cluster 是一种服务端的 sharding 技术，3.0 版本开始正式提供。采用 slot 槽的概念，将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的结点上执行

* 通过哈希的方式将数据分片，每个节点均分存储一定的哈希槽
* 每份数据分片会存储再多个互为主从的多节点上
* 数据写入先写入主节点，再同步到从节点
* 同一个分片多个节点间的数据不保持强一致性
* 读取数据时，当客户端操作的 key 没有分配在该节点上时，redis 会返回转向指令，指向正确的节点
* 在扩容的时候需要把旧节点的数据迁移一部分到新节点



## AKF

https://www.cnblogs.com/-wenli/p/13584796.html



> AKF 立方体理论，定义了系统扩展的 3 个维度，可以综合使用来优化分布式系统的性能
>
> * X 轴： 直接水平复制应用进程来扩展系统
> * Y 轴： 将功能拆分出来扩展系统
> * Z 轴： 站在用户角度，基于用户的信息扩展系统。数据 sharding，分片



<img src="https://s2.loli.net/2022/08/22/xYaOQqiSFnp3omj.png" alt="image-20220822180545860" style="zoom: 33%;" />

---

我们平时见到的各种系统的扩展方案，都可以归结到 AKF 立方体着三个维度上。最初，我们的系统架构是这样的。在这个架构中，**处理业务的应用进程属于无状态服务，用户数据全部放在了关系型数据库中。**



<img src="https://s2.loli.net/2022/08/22/g7dZc9mi1nGfLz8.png" alt="image-20220822180705361" style="zoom: 33%;" />

### X 轴扩展



我们可以在应用进程前加上负载均衡服务，部署更多的应用进程，提高吞吐量。

* 优点是，开发成本低，实施速度快。搭建好负载均衡后，只需要在新的物理机、虚拟机或者微服务上复制程序，就可以分担请求流量，而且不会影响事务的处理

<img src="https://s2.loli.net/2022/08/22/u35rvhk1VEwqjO6.png" alt="image-20220822180830046" style="zoom:33%;" />



### Y 轴扩展

扩展数据库，**读写分离**

当数据库的 CPU、网络带宽等指标率先达到上限后，系统的吞吐量就达到了瓶颈。此时沿着 x 轴扩展系统对性能的提升就不明显了。

Y 轴扩展的核心思想是，拆分系统功能，使得各组件的职责、分工更细

将一个具体的功能聚焦于细分的功能，读写分离，再通过事务组合起来

* 缺点就是：实施成本非常高，涉及到代码重构以及大量的测试，组件 API 之间交互协议 等等
* <img src="https://s2.loli.net/2022/08/22/nP29NyOIdtD4kSC.png" alt="image-20220822181634562" style="zoom:33%;" />

### Z 轴扩展

从用户维度拆分系统，分库分表

比如已经含有上亿行数据的 User 用户信息表，可以分成 10 个库，每个库再分成 10 张表，利用固定的哈希函数，就可以把每个用户的数据映射到某个库的某张表中。每个库部署在不同的服务器上

* 缺点：分库分表虽然是关系数据库中解决数据增长压力的最有效办法，但分库分表导致跨表的查询语句非常复杂，并且跨库的事务几乎难以实现
* Z 轴扩展还有一个好处，就是可以充分利用 IDC 与用户间的网速差，选择更快的 IDC 为用户提供高性能服务。网络是基于光速传播的，当 IDC 跨城市、国家甚至大洲时，用户访问不同 IDC 的网速就会有很大差异。当然，同一地域内不同的网络运营商之间，也会有很大的网速差。
* Z 轴扩展系统时实施成本也比较高，但它基于用户信息拆分数据后，**可以在解决数据增长问题的同时，基于地理位置就近提供服务，进而大幅度降低请求的时延，比如常见的 CDN 就是这么提升用户体验的。**但 Z 轴扩展系统后，一旦发生路由规则的变动导致数据迁移时，运维成本就会比较高。

<img src="https://s2.loli.net/2022/08/22/JcLpyM8jD3eoUai.png" alt="image-20220822182240059" style="zoom:33%;" />

<img src="https://s2.loli.net/2022/08/22/hoN4WArluFi5tak.png" alt="image-20220822182402530" style="zoom:33%;" />



CDN 技术就是基于 IP 地址的位置信息，**就近**为用户提供静态资源的高速访问。



无状态服务（stateless service）对单次请求的处理，不依赖其他请求，也就是说，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以从外部获取到（比如说数据库），服务器本身不存储任何信息

有状态服务（stateful service）则相反，它会在自身保存一些数据，先后的请求是有关联的



### 数据分片



### 一致性哈希

https://zhuanlan.zhihu.com/p/146011745



## 存储 + 缓存， redis 如何设置

关注 redis 的淘汰策略

认为可以淘汰的数据，所有的写操作要加上过期时间

在过期的 key 集合中去淘汰，LRU /LFU

没有设置过期的 key 就是持久化存储



## Redis 数据迁移

常见的 redis 数据迁移方式有三种： AOF（日志文件）、RDB（快照文件）、replication（主从复制）



其中， **aof 和 rdb 两种方式适用于跨网络（网络隔离）的 redis 实例之间的数据迁移**。

* 源实例上执行 `bgsave `生成 aof 或者 rdb 文件
* 下载数据文件
* 上传数据文件
* 启动目标实例
* 完成数据与迁移

rdb 和 aof 的区别，主要体现在数据格式和数据加载速度两个方面。

* aof 是纯文本格式，加载的过程相当于历史重放
* rdb 是二进制格式，可以直接进行加载
* 一般情况下，rdb 更快，建议使用 rdb 做跨网络数据迁移

而 **replication 方式，适用于同一网络内的 redis 实例之间的数据迁移**，在目标实例上通过指令 `slaveof `完成数据全量复制迁移。在单实例的扩容应用上最合适





## Epoll

epoll和poll的一个很大的区别在于，poll每次调用时都会存在一个将pollfd结构体数组中的每个结构体元素从用户态向内核态中的一个链表节点拷贝的过程，而内核中的这个链表并不会一直保存，当poll运行一次就会重新执行一次上述的拷贝过程，这说明一个问题：**poll并不会在内核中为要监听的文件描述符长久的维护一个数据结构来存放他们，而epoll内核中维护了一个内核事件表，它是将所有的文件描述符全部都存放在内核中，系统去检测有事件发生的时候触发回调**，当你要添加新的文件描述符的时候也是调用epoll_ctl函数使用EPOLL_CTL_ADD宏来插入，epoll_wait也不是每次调用时都会重新拷贝一遍所有的文件描述符到内核态。当我现在要在内核中长久的维护一个数据结构来存放文件描述符，并且时常会有插入，查找和删除的操作发生，这对内核的效率会产生不小的影响，因此需要一种插入，查找和删除效率都不错的数据结构来存放这些文件描述符，那么红黑树当然是不二的人选。



> 其实红黑树的作用是仅仅是在管理大量连接的情况下，添加和删除 socket 非常的高效。如果 epoll 管理的 socket 固定的话，在数据收发的事件管理过程中其实红黑树是没有起作用的。内核在socket上收到数据包以后，可以直接找到 epitem(epoll item)，并把它插入到就绪队列里，然后等用户进程把事件取走。这个过程中，红黑树的作用并不会得到体现。

































