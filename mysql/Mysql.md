# Mysql

![img](https://s2.loli.net/2022/08/13/RFGSr6vf24KnMYu.png)



![image-20220813091031645](https://s2.loli.net/2022/08/13/Gw1x3hVqP9pTQmI.png)







## 谈一下你对 mysql 索引的理解

> 但凡谈到索引，一定要谈到两个层面！
>
> * **IO**
> * **数据结构**

**IO：**

mysql 中所有的数据都是存在磁盘里面的，不管是行数据还是索引数据，都是保存在磁盘里面的。既然保存在磁盘，IO就是瓶颈。所以，我们要尽可能少的从磁盘中取数据

这个少有两个维度

第一个维度，读取次数少，

第二个维度，量少

不可能一口气把所有磁盘文件都加载到内存，所以要考虑一件事，分块读取。

分块读取，要提到两个知识点：**局部性原理，磁盘预读**，

**之后就是数据结构：**

B+树为什么好

哈希表 -> 二叉树 -> AVL 树 -> 红黑树 -> B树 -> B+ 树



mysql 的 B+ 树是 mysql 索引系统里面最主要的存储结构，除了 B+ 树，还有哈希表，只不过针对的是不同的存储引擎，memory 存储引擎是哈希表，innodb myisam 是 B+ 树

在使用索引的时候，为了提高我们整体数据的查询效率，要尽可能少的从磁盘中读取数据，同时要保证我们读取的数据足够有效，不可能一口气将磁盘中所有数据整个读取。怎么做的呢，就是局部性原理，磁盘预读。**在读取数据的过程中，涉及到一个概念叫分块读取，在考虑分块读取的时候 mysql 存储系统里面，磁盘和内存在进行交互的时候，并不是按需读取，是以 页 为单位的，一次至少读一页数据，我们在进行数据读取的时候，一般都是 页大小 的整数倍，innodb 的存储引擎，默认读取的是 16kb**

为什么要使用 B+ 树呢？ 。。。。。。见后面





---



Mysql 中存在一些索引，**目的是为了加快我们数据访问的速度**，索引底层的数据结构是通过 B+ 树，或者哈希表进行生成的。

* 对于不同类型的索引，是跟我们的**存储引擎**相关的。如果我们使用 Myisam 或者 innodb 这种存储引擎，那么对应底层的数据结构就是 B+ 树，memory 这种存储引擎对应的就是哈希表。



* 为什么有这样的特点，**因为不同存储引擎表示的是数组在磁盘上面不同的组织形式**。
  * 为什么 innodb  和  Myisam 要使用 B+ 树呢，
  * 原因在于，我们要想存储数据的话，首先要了解索引中存储的是什么类型的数据，一般是根据某个 key 找到对应的 value，key 就是我们索引某个列的值， value 就是一行的记录，当我在选择这种  key value 这种格式存储的时候，有很多**数据结构**可以选择，比如 二叉树 AVL 树 红黑树 B+ 树等等，最根本的点在于，不管我们用任何一种类型的二叉树，最终都会导致我们的树变高，从而增加我们的 io 次数，影响我们整体数据访问的效率。因此使用了 B+ 树结构，可以在某一个数据结点中，尽可能多的存储数据，让这棵树变低，减少 IO 次数。
* Mysql 中有**主键索引，唯一索引，组合索引等各种分类**，我们在日常工作中，用的最多的可能是主键索引和组合索引。主键索引和组合索引在应用的时候会存在一系列**回表、最左匹配、索引下推等**细节点。
* 在使用 sql 语句的时候，当你执行了一个 sql 语句的时候，我们还可以通过索引的一些点来进行优化，提高对应数据的访问形式。



![image-20220813200539733](https://s2.loli.net/2022/08/13/a6oAk4vzjCZu3y2.png)



---

### 存储引擎

* 存储引擎：**数据在磁盘上的不同组织形式**，不同的存储引擎可能用同样的数据结构，但是在磁盘中存储的时候，文件和格式都是不一样的
  * 无论 Innodb 还是 myisam 索引数据结构都是 B+ 树
  * Innodb
    * 支持事务
    * 支持外键
    * 支持表锁和行锁（锁力度）
    * 索引存储的方式和 myisam 不同
    * 支持自适应 哈希，用户不可以干扰
  * myisam
    * 不支持事务
    * 不支持外键
    * 只支持表锁
* 哈希表也可以作为索引的数据结构，但是必须是 memory 存储引擎



### 数据结构

> 减少 io 次数 + 减少 io 的量

* 为什么 IO 次数多了程序就慢了
  * 局部性原理
    * 时间局部性和空间局部性
    * 数据和程序都有聚集成群的倾向，读取数据的时候，读取的不是一个字符，而是一块区域
    * 之前被读取过的数据有可能很快被下一次读取
  * 磁盘预读
    * 如果我需要读取一个字符 a 从磁盘中，内存和磁盘在进行数据交互的时候有一个最基本的逻辑单元，称为 页(data page)
    * 不同的操作系统页的大小是不同的，一般是 4k 或者 8k，每次需要读取 4k 的整数倍
    * innodb 默认读取的是 16kb



**<u>为什么使用 B+ 树？</u>**

Mysql 中存在一些索引，索引底层的数据结构是通过 B+ 树，或者哈希表进行生成的

* 哈希表：
  * 使用哈希表必须保证具备好的哈希算法，如果算法不合适的话会造成哈希冲突或者哈希碰撞，会导致**数据散列不均匀，有可能退化成链表**
  * 使用哈希表的时候**不支持范围查询**，当需要范围匹配的时候，必须要挨个对比，效率太低
  * 需要大量内存空间
  * memory 存储引擎本身就是基于内存的，因此使用了哈希表
* 二叉树、AVL 树、红黑树、B 树
  * 分支有且仅有两个
  * 因此，当我们想要存储更多的数据，**<u>树的高度就会增加</u>**，<u>那么 **IO 次数**就会增加</u>，<u>程序就会变慢</u>，
  * **因此我们考虑将二叉树变为多叉树，同时保证有序性的特点**，因此就考虑到了 B 树，B树的特点是，索引和数据保存在一起，就意味着，每次在读取数据的时候，每个块会保存着索引数据和实际数据，而**实际数据读出来以后，会占用大量存储空间，就导致了树的分支范围变小**，范围变小之后，就导致插入数据的时候，树的高度又会增加，IO 时间就会增加，效率就会变慢。基于这一点，要考虑将 B 树中的非叶子结点只存储 key 的值，非叶子结点存储实际数据，依托于这样的变化，就得到我们的 B+ 树
  * 但是，B+ 树能够稳定查询效率，**因为数据都保存在叶子结点上，非叶子结点只存储 key 的值**，整个树高又相对稳定，因此不论查询哪条数据，效率都是稳定的
  * B + 树能够提高**范围查询**的效率，因为每个叶子节点都有指向下一个节点的指针
  * 两种**数据访问方式**
    * 从根节点开始
    * 从叶子结点开始，链表，顺序查找



---

B 树

![image-20220813204950488](https://s2.loli.net/2022/08/13/aeIy1J6GLuP5pXA.png)

* **每个节点中既包含数据，又包含指针**
* 那么，一个三层 B 树最多能存多少数据呢？
* 假设每条数据是 1 Kb，指针不占空间， 16 * 16 * 16 = 4096



* **改进 ： 叶子结点放全量数据，非叶子节点中不放 data，只存索引**
*  假设一个指针占用 10 个字节， 1600 * 1600 * 16 = 40960000  （1600 = 16k / 10）
* Mysql 中的 B+ 树，千万级别数据量，三到四层就足够了
* <u>**key 是选用 int 还是 varchar**</u> ？ -> 索引大小，越小越好！
  * 索引占用空间越小，树就越矮
* <u>**id 列要不要自增**</u> -> 要
  * 避免页分裂，能自增就自增
* 两种数据访问方式
  * 从根节点开始
  * 从叶子结点开始，链表，顺序查找

![image-20220813205925263](https://s2.loli.net/2022/08/13/HeMqfk8dbCWg4p1.png)



### 聚簇索引和非聚簇索引

问区别的时候，先说一句话：

聚簇索引也好，非聚簇索引也好，只是索引的一个基本分类，**他们最本质上的点在于存储引擎**（**一定要把存储引擎给说清楚**）

> 数据和索引**放在一起存储**的成为聚簇索引，**没有放在一起存储**的称为非聚簇索引
>
> 下面为例， id 是聚簇索引， name 是非聚簇索引
>
> 在 innodb 存储引擎中，即存在聚簇索引，又存在非聚簇索引，存放数据的有 idb 文件
>
> 在 myisam 存储引擎中，只有非聚簇索引，存放数据的是 myi 和 mdi 文件

**存在的原因**

一个表中具备多个索引的时候，就表示产生了多颗 B+ 树，**不可能在每颗 B+ 树中都保存完整的数据，这样的话会导致数据冗余**，因此数据和索引放在一起的称为聚簇索引，**其他索引存放的是聚簇索引的 key 值 ，通过回表的方式查询到具体数据**。



![image-20220813211533649](https://s2.loli.net/2022/08/13/mNDu2WYqdwj9Cnc.png)



* Innodb **存储引擎，在插入数据的时候，数据必须和某个索引列绑定，放在一起 "idb"**
  * 索引列，**可以是主键，也可以是唯一键**，也可以是 **6 字节的 row_id**（int 类型 4 个字节，上亿的数据，一定要分库分表了）
* 一个表中可以包含多个索引列，那么数据文件会存储几份？
  * 数据仅仅存储一份，不会造成多份数据的荣誉
* 数据根某一个索引列是绑定到一起的，那么其他索引列如果检索数据呢？
  * 会将根数据绑定到一起的**索引列的值**放到**其他索引的叶子结点**
  * 如下图，首先根据 name 查询 id，再根据 id 查询到我们整个数据的结果

![image-20220813212304077](https://s2.loli.net/2022/08/13/LlNJWdR68FOerGc.png)

---

<u>在 myisam 存储引擎中，只有非聚簇索引，叶子结点放的是地址，“ myi , myd”</u>

![image-20220813212622464](https://s2.loli.net/2022/08/13/vLenF6df2rhY7qK.png)



### mysql 索引的使用原则

#### 索引怎么使用才合理？

我们容易有一个误区，就是在经常使用的查询条件上都建立索引，索引越多越好。事实上并不是这样。

* 首先，创建索引的过程会创建树，大量创建索引会消耗大量的原本用来存放数据的磁盘空间，从这一点上，索引的个数不要过多

* 第二点涉及到一个概念叫 列的离散度，列不同值的数量 / 总行数，越接近 1，离散度越高，反之越低。离散度越接近 0 ，区分度低的字段，越不推荐建立索引，因为有大量重复值，可以考虑分表存储
* 第三点，频繁更新的值，不要作为主键或者索引，否则容易导致页分裂
* 随机无序的值，不建议作为索引，例如身份证
* 创建复合索引，而不是修改单列索引
* 在 用于 where 判断 order 排序 和 join on 的字段上创建，不要在要查询的select 后面的字段上创建

---



#### 组合索引的一些细节问题

![img](https://s2.loli.net/2022/08/14/HB2MramRoFcYP6Q.png)

有时候，我们使用多条件查询，会建立组合索引

组合索引在 B+ 树中是复合的数据结构，按照从左到右的顺序来建立搜索树

![image-20220814223914523](https://s2.loli.net/2022/08/14/8RpA4IcFibU3MqH.png)

---





![image-20220813213544227](https://s2.loli.net/2022/08/13/EJHDGKIk9FbT6YZ.png)

##### 回表

* 从某一个索引的叶子节点中，获取聚簇索引的 id 值，再根据 id 值从聚簇索引中获取全量数据的过程

* 尽量减少回表查询

##### 索引覆盖

* 从索引的叶子结点中能获取到**全量查询列**的过程叫做索引覆盖（select 的数据列只用从索引中就能取得，不必从数据区中读取）



---

![img](https://s2.loli.net/2022/08/13/BCIlQv1LtsSmqwA.png)

##### 最左匹配

* mysql 优化器会进行优化，选择合适的顺序来执行



![img](https://s2.loli.net/2022/08/13/yVj4q2CdT6SEaQt.png)

##### 索引下推

* mysql 5.7 开始出现
* 原来在 server 层要进行操作，下推到存储引擎层

* 在没有索引下推之前，sql 语句执行过程如下
  * 先根据 name 去存储引擎拿全量的数据
  * 将数据读到 server 层
  * 在 server 层按照 age 做数据过滤
* 有索引下推之后
  * 根据 name，age 两个列去存储引擎筛选数据
  * 将最终的结果返回给客户端



### 什么时候索引失效

在索引的值不确定的情况下，九种情况，硬背

* 索引上做一些特定操作，计算，函数，类型转换

---

* 组合索引不遵循最左匹配原则

* 组合索引的前面索引列使用范围查询(< > like)，会导致后续的索引失效。注意，大于等于不会

---

* 两表关联使用的条件字段中字段的长度、编码不一致，索引失效（触发隐式转换）

* ---

  字符串不添加引号

* like 语句中，以 % 开头的模糊查询（后面百分号没问题），如何解决？使用覆盖索引

---

* is null 和 is not null 无法使用索引

* 使用 or 操作符，左右两边的查询列索引不同，在连接的时候索引会失效。

  ---

  

* 如果 mysql 中使用全表扫描比使用索引块，也会导致索引失效

  * 解决方式：
    * optimize table xxx
    * force index ，强制索引



还有几种情况不太确定

* 使用 in 的时候，有时候失效，有时候不失效



## BinLog 

* BinLog 是什么，有什么用？
* 数据库被人干掉了怎么办
* 数据恢复，主从复制

MySQL Server 层有一个日志文件，叫做 binlog，它可以被所有的存储引擎使用

**BinLog 以事件的形式记录了所有的 DDL 和 DML 语句**（因为它记录的是操作而不是数据值，属于逻辑日志），可以用来做主从复制和数据恢复



* 假如数据库表被删，我们可以基于全量备份的数据 + BinLog 将数据**恢复到删除时刻**的样子
* 主从复制，写操作只会在主节点操作，读操作可以分担到从结点上
* 从结点读取主结点发生变化的内容，解析出来，在自己的结点上执行



数据恢复：区别于 RedoLog 的崩溃恢复，数据恢复是基于业务数据的，比如删库跑路，而崩溃恢复是断电重启的



## 预读

磁盘读写，并不是按需读取，而是按页读取，一次至少读一页数据（一般是 4K，但 Mysql 的数据页是 16K），如果未来要读取的数据就在页中，就能够省去后续的磁盘 IO，提高效率

局部性原理

**<u>16KB   -> 16384 一万六千三百八十四字节</u>**

## Buffer Pool

这也是性能优化的一个点

缓存表数据与索引数据，把磁盘上的数据加载到缓冲池，避免每次都进行磁盘 IO，起到加速访问的作用



## Buffer Pool 内存淘汰策略

冷热分区的 LRU 策略

LRU 链表会被拆分成两部分，一部分为热数据，一部分为冷数据，冷数据占比 3/8，热数据 5/8

* 数据页第一次加载进来放在 冷数据区 头部
* 冷数据区域的缓存页，什么时候放入热数据区域？
  * MYSQL 设定了一个规则，在 innodb_old_block_time 参数中，默认为 1000 毫秒
  * 意味着，只有把数据页加载进缓存里，在经过 1 秒之后再次对缓存页进行访问才会将缓存页放到 LRU 链表热数据区域的头部
* 为什么是 1 秒
  * 因为通过预读机制和全表扫描加载进来的数据页通常是 1 秒就加载了很多，然后对他们访问一下，这些都是 1 秒内完成，他们会放在冷数据区等待刷盘清空，基本上不太有机会放到热数据区域，除非在 1 秒内有人访问，说明后续可能还会有人访问，才会放在热数据区域头部





## RedoLog 和 BufferPool 的关系

崩溃恢复 基本保障 系统自动做的

> InnoDB 引入了一个日志文件，叫做 redoLog（重做日志），我们把所有对内存数据的修改操作写入日志文件，如果服务器出问题了，我们就从这个日志文件里面读取数据，恢复数据 --- 用它来实现事务的持久性



* RedoLog 的 特点
  * 记录修改后的值，属于物理日志 （存的是具体的数值，不是 sql）
  * 大小固定，前面的内容会被覆盖，所以不能用于数据回滚/数据恢复
  * redoLog 是 InnoDB 引擎实现的，并不是所有存储引擎都有



## 一条查询语句是怎么执行的

* mysql 默认连接数 151，最大十万

* 默认，八小时不活动，断开连接

  

![image-20220814210917267](https://s2.loli.net/2022/08/14/jwSzMDHqpCyRLvf.png)

**“连 分 优 执”   ： 连接器，分析器，优化器，执行器   -> 存储引擎**

1. 客户端用来建立连接，发送请求
2. 验证权限（连接器）
2. 查取缓存

   * mysql 内部自带了一个缓存模块，默认是关闭的，mysql 5.8 中已经被移除

   * mysql 的缓存（注意，不是内存缓存）是表级别的，比较鸡肋，表中任意一行数据变化，缓存就会失效
2. 词法解析，语法分析，预处理

   * 词法解析：将一个完整的 SQL 打碎成单词

   * 语法解析：对 SQL 语句做一些语法检查，比如单引号有没有闭合，然后根据 MYSQL 定义的语法规则，根据 SQL 语句生成一个数据结构，称为**解析树**
   * 预处理：检查生成的解析树，解决解析器无法解析的语义。比如检查表明、列名是否存在，如果表名错误，会在预处理时报错，这一步的目的是，保证没有歧义
5. 查询优化

   * 一条 SQL 语句可以有多种执行方式，MYSQL 查询优化器的模块，根据解析树生成不同的执行计划，然后选择一种最优的
   * 优化器中包含两个模块，CBO 和 RBO
     * CBO：基于成本的优化
     * RBO：基于规则的优化
     * MYSQL 中使用的是 CBO，哪种执行计划开销小，就用那种
   * 使用命令 show status like '"Last_query_cost"'   :  需要随机读取几个 4k 数据页才能完成查找
   * 另外，对于一些恒等式，会在这一步被去掉，还有小表驱动大表
4. 执行计划

   * 经过优化以后，**我们会得到一个最优的执行计划**，交给执行器，通过API调用 存储引擎获取数据，返回结果

---

以上的方式是简单的描述方式，是通过架构体系聊的。其实我们的 Mysql 在执行的时候，当客户端提交一条 sql 到服务端以后，会先把执行语句**加载到内存中**，然后查看执行语句的类型，select/update/insert/delete，其中 select  需要优先将执行语句加载到内存中，而 update/insert/delete 必须要读取数据结果，放到内存中

![img](https://s2.loli.net/2022/08/15/Bpjfz9qCP47URct.png)

![image-20220815155633283](https://s2.loli.net/2022/08/15/1PtiflsrbFy27hw.png)



两阶段提交

![image-20220815160935563](https://s2.loli.net/2022/08/15/HJRBQNuOSzep5Zs.png)

![image-20220815161510700](https://s2.loli.net/2022/08/15/LiNGqUpjuhS96Iz.png)





## 更新语句和查询语句执行流程是否一样？



![image-20220814213746379](https://s2.loli.net/2022/08/14/4HATmuZbLfY5GOJ.png)



1. SQL 语句传入
2. 根据 sql 语句的条件，首先执行查询的流程（见前文），查询出我们需要的数据，进行修改
3. 将修改结果更新早内存中 bufferPool，新写入的叫做脏页，需要等待 **刷脏**，也就是写入到磁盘
   * <u>刷脏有很多种情况。磁盘默认 1 秒一次，redoLog满了刷脏， buffPool 满了刷脏</u>
4. 记录 redoLog，并且及那个这行记录状态设置为 prepare
5. 修改好了，可以提交事务
6. 写入 binLog
7. commit ，真正提交事务
8. redoLog  里将这个事务的状态，设置为 commit。（redoLog 要在整个事务真正 commit 之后才会更改状态为 commit）



## 磁盘如何完成单次 IO

1. 盘片
2. 磁头
3. 主轴
4. 集成电路板

单次 IO 的时间 ： **寻道时间 （3-15 ms） +  旋转延时 + 传送时间**

磁头移动到数据所在的磁道 + 磁道旋转 + 数据传送

### 顺序读和随机读的区别

B+ 树可以顺序访问

顺序读的话，可以连续访问 io，读完一条数据可以马上读取下一条

随机读的话，读完一条数据，需要重新等待寻道 + 旋转延时



![image-20220814220402244](https://s2.loli.net/2022/08/14/cBU12DQOLuFpNfg.png)





### 顺序 io 和并发 io 的区别

单个磁盘一次只能处理一个 io

多个磁盘、磁盘组可以处理多个 io



### 机械硬盘 、 固态 的区别

机械硬盘的原理：

* **电磁存储**;机械硬盘在盘面上写数据、磁盘转动，机械臂移动，也是比较原始的数据读写方式，就像近现代的留声机发声原理一样。
* **往机械硬盘上面写入数据的过程，就是由磁头改变盘片上面微小磁铁的磁场方向的过程**（2个相反的磁场方向，分别表示0和1）

固态硬盘的原理：

* 半导体存储;数据直接存在**闪存颗粒中**，并且由**主控单元记录数据存储位置和数据操作**，每一个闪存颗粒的存储容量是有限的;
* 主控芯片 + 闪存颗粒。主控芯片负责传输，闪存负责存储。闪存中包含了无数个存储单元，主控芯片可以**直接定位到存储单元中的数据**
* 固态硬盘的存储单元可以看做是小小的电容，**往固态硬盘上面写入数据的时候，其实就是对这些微小电容进行充电或者放电**



## 描述一下数据库的隔离级别

> 答题思路：
>
> 从数据库事务的四个特性开始，解释清楚 四种隔离级别 +  产生的问题

先说明一个事儿

数据库的事务支持四个特性，acid，**原子性，一致性，隔离性，持久性**

* 原子性： undo log
* 一致性：通过原子性、隔离性、持久性保证实现。最核心，最本质的要去
* 隔离性：锁+并发调度（多版本并发控制）
* 持久性：redo log

**隔离性是其中的一个特性**，为了提高我们一系列的并发性能

而隔离级别本身有四种级别，分别是，读**未提交、读已提交、可重复读、串行化**。

他们分别解决了**脏读、幻读、不可重复读**的相关问题。

而选择隔离级别需要根据具体应用场景来确定，因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 RC，特殊的是，Innodb 使用的是 RR，可重复读

* 脏读：当我们有两个及以上事务操作数据库的时候，<u>无论第二个事务是否有提交动作，第一个事务都会读到最新版本。</u>（简单来说，事务能够读取未提交的数据）。压根没有隔离性
* 不可重复读：事务 A 执行过程中，数据被另一个事务 B 修改，造成本次执行的事务 A 前后读取信息不一样
* 幻读：当事务A读取**某一个范围的数据**，另一个事务B在这个范围插入行，A事务再次读取这个范围的数据，会产生幻读。（事务 A 在读取数据的时候，事务 B 插入了相同搜索条件的新数据，事务 A 再次按照原来的条件进行读取的时候，读取到了事务 B 插入的新数据 ）
  * 谈到幻读，首先分析当前读和快照读
  * 幻读有一个重点必须要注意：什么时候会产生幻读？**当前读和快照读混合使用的时候才会产生幻读**，全部使用快照读并不会产生幻读问题。
  * 解决幻读，使用临键锁


### 隔离级别实现原理

事务的隔离机制的实现，**基于锁机制和并发调度**，**其中并发调度使用的是 MVCC**（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等操作

### MVCC用什么实现

三个隐式字段，undo日志、read view三个组件来实现的，原理见 MVCC 文档





## MVCC

MVCC，也就是多版本并发控制，一般在数据库管理系统中实现对数据库的并发访问



### **当前读**

​		像<u>select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)</u>这些操作都是一种当前读，为什么叫当前读？就是它**读取的是记录的最新版本**，**读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁**。

### **快照读（提高数据库的并发查询能力）**

​		**像不加锁的select操作就是快照读，即不加锁的非阻塞读**；**快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读**；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

### **当前读、快照读、MVCC关系**

​		MVCC多版本并发控制指的是维持一个数据的多个版本，使得读写操作没有冲突，快照读是MySQL为实现MVCC的一个非阻塞读功能。MVCC模块在MySQL中的具体实现是由**三个隐式字段，undo日志、read view三个组件来实现的**。



### MVCC 解决的问题

数据库并发场景有三种：

* 读读：不存在任何问题，也不需要并发控制
* 读写：有线程安全问题，可能会造成事务隔离性的问题，可能遇到脏读、幻读、不可重复读
* 写写：有线程安全问题，可能存在更新丢失的问题

**MVCC 是一种用来解决读写冲突的，无锁并发控制。**也就是为事务分配单项增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库快照，所以 MVCC 可为数据库解决以下问题：

* 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的能力
* 解决脏读、不可重复读、幻读等读事务隔离性的问题，但是不能解决更新丢失的问题



### 实现原理





### **undo log**

​		**undolog被称之为回滚日志，表示在进行insert，delete，update操作的时候产生的方便回滚的日志**

​		当进行insert操作的时候，产生的undolog只在事务回滚的时候需要，并且在事务提交之后可以被立刻丢弃

​		**当进行update和delete操作的时候，产生的undolog不仅仅在事务回滚的时候需要，在快照读的时候也需要，所以不能随便删除**，只有在快照读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除（当数据发生更新和删除操作的时候都只是设置一下老记录的deleted_bit，并不是真正的将过时的记录删除，因为为了节省磁盘空间，innodb有专门的purge线程来清除deleted_bit为true的记录，如果某个记录的deleted_id为true，并且DB_TRX_ID相对于purge线程的read view 可见，那么这条记录一定时可以被清除的）

### **Read View**

​		上面的流程如果看明白了，那么大家需要再深入理解下read view的概念了。

​		**Read View是事务进行快照读操作的时候生产的读视图**，在该事务执行快照读的那一刻，会生成一个数据系统当前的快照，记录并维护系统当前活跃事务的id，事务的id值是递增的。

​		**其实Read View的最大作用是用来做可见性判断的**，也就是说当某个事务在执行快照读的时候，对该记录创建一个Read View的视图，把它当作条件去判断当前事务能够看到哪个版本的数据，有可能读取到的是最新的数据，也有可能读取的是当前行记录的undolog中某个版本的数据

## mysql 幻读怎么解决

事务 A 在读取数据的时候，事务 B 插入了相同搜索条件的新数据，事务 A 再次按照原来的条件进行读取的时候，读取到了事务 B 插入的新数据 

如果我们在进行查询的时候，全部使用快照读，是不会出现幻读问题的，只有快照读和当前读混合使用才会出现幻读问题

如果出现幻读问题，我们一般通过 select for update 解决，本质上是使用了临键锁



补充细节知识：

<u>innodb 没有索引，锁表，有索引，锁行</u>

<u>除了 select ，其他都是当前读</u>







## RC、RR级别下的InnoDB快照读有什么不同

MVCC 核心：

> 在 RC 隔离级别下，**每个快照读**都会生成并获取最新的 ReadView，而在 RR 隔离级别下，则是**同一个事务第一个快照读**才会创建 ReadView，之后的快照读获取的都是同一个 ReadView



## 监控锁情况

```
show engine innodb status\G
```





## sql join 原理

MySQL是只支持一种Join算法Nested-Loop Join(嵌套循环连接)，并不支持哈希连接和合并连接，不过在mysql中包含了多种变种，能够帮助MySQL提高join执行的效率。

​		**1、Simple Nested-Loop Join**

​		这个算法相对来说就是很简单了，从驱动表中取出R1匹配S表所有列，然后R2，R3,直到将R表中的所有数据匹配完，然后合并数据，可以看到这种算法要对S表进行RN次访问，虽然简单，但是相对来说开销还是太大了。

![image-20220815125053521](C:\Users\Fannsy\AppData\Roaming\Typora\typora-user-images\image-20220815125053521.png)

​		**2、Index Nested-Loop Join**

​		索引嵌套联系由于非驱动表上有索引，所以比较的时候不再需要一条条记录进行比较，而可以通过索引来减少比较，从而加速查询。这也就是平时我们在做关联查询的时候必须要求关联字段有索引的一个主要原因。

​		这种算法在链接查询的时候，驱动表会根据关联字段的索引进行查找，当在索引上找到了符合的值，再回表进行查询，也就是只有当匹配到索引以后才会进行回表。至于驱动表的选择，MySQL优化器一般情况下是会选择记录数少的作为驱动表，但是当SQL特别复杂的时候不排除会出现错误选择。

​		在索引嵌套链接的方式下，如果非驱动表的关联键是主键的话，这样来说性能就会非常的高，如果不是主键的话，关联起来如果返回的行数很多的话，效率就会特别的低，因为要多次的回表操作。先关联索引，然后根据二级索引的主键ID进行回表的操作。这样来说的话性能相对就会很差。

![image-20220815125030892](https://s2.loli.net/2022/08/15/rvblphGOJsyxVjL.png)

​		**3、Block Nested-Loop Join**

​		在有索引的情况下，MySQL会尝试去使用Index Nested-Loop Join算法，在有些情况下，可能Join的列就是没有索引，那么这时MySQL的选择绝对不会是最先介绍的Simple Nested-Loop Join算法，而是会优先使用Block Nested-Loop Join的算法。

​		Block Nested-Loop Join对比Simple Nested-Loop Join多了一个中间处理的过程，也就是join buffer，使用join buffer将驱动表的查询JOIN相关列都给缓冲到了JOIN BUFFER当中，然后批量与非驱动表进行比较，这也来实现的话，可以将多次比较合并到一次，降低了非驱动表的访问频率。也就是只需要访问一次S表。这样来说的话，就不会出现多次访问非驱动表的情况了，也只有这种情况下才会访问join buffer。

​		在MySQL当中，我们可以通过参数join_buffer_size来设置join buffer的值，然后再进行操作。默认情况下join_buffer_size=256K，在查找的时候MySQL会将所有的需要的列缓存到join buffer当中，包括select的列，而不是仅仅只缓存关联列。在一个有N个JOIN关联的SQL当中会在执行时候分配N-1个join buffer。

![image-20220815125042375](https://s2.loli.net/2022/08/15/7oMS1JINVE8rgCy.png)





## mysql 如何做分库分表的

使用 mycat 或者 shardingsphere 中间件做分库分表，选择合适的中间件，**水平分库，水平分表，垂直分库，垂直分表**，相比而言水平多一些，垂直少一些

在进行分库分表的时候尽量遵循一下原则：

* 能不切分，尽量不要切分。<u>数据量达到一定规模，无法继续优化查询效率，一般来说千万级数据需要切分，百万级也有可能，在表字段占用存储空间比较多的时候</u>
* 如果一定要切分，选择合适的切分规则，提前规划好
* 数据切分尽量通过数据冗余或者表分组来降低跨库 join 的可能
* 由于数据库中间件对数据 join 实现的优劣难以把握，而且实现高难度性能难度很大，业务读取尽量少使用多表 join。



[MySQL高可用架构对比，MMM与MHA以及MGR](https://blog.csdn.net/William0318/article/details/106855431)

暂时没有用过 分布式mydql 这些分库分表的组件，但我私下了解过一些

分库分表的中间件有 mycat ，shardingsphere 还有 阿里的**cobar**，现在的话 shardingsphere  生态是比较友好的，mycat 生态不友好，cobar 是阿里的。工作中需要根据实际情况进行选择。我个人的话推荐 shardingsphere ，他提供的组件会越来越完整。

shardingsphere  包括的组件包括 ........ 按照上述网站整理





## 主从复制、读写分离

主从复制就是保证一件事， master 和 slave 中的数据必须是一模一样的。怎么做，基于 binLog。

master 每次更新都会将操作写入到 binLog，在我们的 slave 中，有一个线程叫 IO THREAD，会定时访问 binLog，把变化后的 binLog 拿过来放到 slave 中的**中继日志 relayLog** 里面，在 slave 中有另外一个线程 **sqlThread**，由  sqlThread 调用 relayLog进行一个操作叫 replay，之后把 sql 语句执行到 slave 里面去。

详细见主从复制文档



### 为什么会有 relayLog？replay 的意义是什么？

保证效率，减少随机IO，增加顺序IO



### mysql 主从同步延时分析

mysql 的主从复制都是单线程的操作，主库对所有 DDL 和 DML 产生的日志写进 binLog，由于 binLog 是顺序写，所以效率很高，**slave 的 sql thread 线程将主库的 DDL 和 DML 操作事件在 slave 中重放**。DML 和 DDL 的 IO 操作都是 随机的，不是顺序，所以 成本要高很多。另一方面，由于 sql thread 也是单线程的，当主库的并发较高，产生的 DML 数量超过 slave 的 sql thread 所能处理的速度，或者当 slave 中 有大型 query 语句产生了所等待，那么延时就产生了。



**mysql 5.7 之后使用 MTS 并行复制技术，永久解决复制延时问题**



## Myiaam 和 Innodb 区别

show engines;



| 区别     | Innodb                         | MyISAM           |
| -------- | ------------------------------ | ---------------- |
| 事务     | 支持                           | 不支持           |
| 外键     | 支持                           | 不支持           |
| 索引     | 即支持聚簇索引又支持非聚簇索引 | 只支持非聚簇索引 |
| 行锁     | 支持                           | 不支持           |
| 表锁     | 支持                           | 支持             |
| 存储文件 | frm，ibd                       | frm,myi,myd      |
| 具体行数 | 每次必须要全表扫描统计行数     | 通过变量保存行数 |

如何选择？

​		1、是否需要支持事务，如果需要选择innodb，如果不需要选择myisam

​		2、如果表的大部分请求都是读请求，可以考虑myisam，如果既有读也有写，使用innodb

​		现在mysql的默认存储引擎已经变成了Innodb,推荐使用innodb





## 如何优化 sql，查询计划的结果中看哪些关键数据

id

type：访问类型，效率最低 ALL， 效率最高 system，保证查询在 range 以上

key：实际使用的索引，如果为 null，则没有使用所用，查询中若使用了覆盖索引，则该索引和查询的 select 字段重叠

key_len：索引中使用的字节数，可以通过 key_len 计算查询中使用的索引长度，在不损失精度的情况下长度越短越好





## 表很大，性能下降，对吗？

如果表有索引

* 增删改，变慢，因为要维护索引
* 查询操作
  * 如果只是一个或少量查询，依然很快，因为命中索引后仍然只是读取命中的内存块，没有命中过的不会加载到内存
  * 如果是并大大时候，会受到硬盘带宽影响速度。4K 一个一个走，后面等待前面







## 描述一下 mysql的乐观锁、悲观锁、锁的种类

乐观锁不是数据库自带的，如果需要使用乐观锁，那么需要自己去实现，一般情况下，我们会在表中新增一个 version 字段，每次更新数据 version + 1，在进行提交之前会判断version 是否一致

mysql 中的绝大部分都是悲观锁，按照粒度可以分为表锁和行锁

**行锁**

共享锁：当读取一行记录的时候，为了防止别人修改，则需要添加 S 锁

排他锁：当修改一行记录的时候，为了防止别人同时修改，则需要添加 X 锁

记录锁：添加在行索引上的锁

间隙锁：锁定范围是索引记录之间的间隙，针对可重复读以上隔离级别

临键锁： 记录锁 + 间隙锁

```Java
lock table table_name  //myisam 加锁方式
// 查看锁的信息
show engine innodb status\G;

show variables like '%innodb_status%';
set global  innodb_status_output_locks=1; // 必须将 这个参数设置为 on，才能看到
```



---

**表锁**

意向锁：在获取某行的锁之前，必须要获取表的锁，分为意向共享锁，意向排他锁

自增锁：对自增字段锁采用的特殊表级锁



锁模式的含义：

* IX：意向排他锁
* X：锁定记录本身和记录之前的间隙
* S：锁定记录本身和记录之前的间隙
* X,REG_NOT_GAP: 只锁定记录本身
* X,GAP: 间隙锁，不锁定记录本身
* S,GAP：间隙锁，不锁定记录本身
* X,GAP,INSERT_INTENTION: 插入意向锁





![image-20220816093047467](https://s2.loli.net/2022/08/16/2ZnQpdFTtGlLj5C.png)

![image-20220816093751203](https://s2.loli.net/2022/08/16/QI9r6uAqV4mGoia.png)



---



**如果发现死锁和锁冲突怎么办？**

首先开启一个属性是，innodb_lock_output，开启之后使用

```Mysql
show engine innodb states // 打印相关事务信息
```

打印相关事务信息

我们会看到当前行的一些锁信息

IX：意向排他锁

X： 零间锁，锁定范围是当前行记录，以及间隙



![image-20220815160707074](https://s2.loli.net/2022/08/15/MoTRsgr14WkzIJn.png)



<img src="https://s2.loli.net/2022/08/15/vsONTFJzVwGUlAM.png" alt="image-20220815155823964" style="zoom:50%;" />

