# 多线程

## 进程、线程和协(纤)程

### 什么是进程，什么是线程？

* 进程是**操作系统**资源分配的基本单位，linux 中称为 task，用进程描述符 PCB 进行管理
* 线程是操作**系统调度的基本单位**，共享进程的内存空间，但**每个线程有自己的程序计数器，虚拟机栈和本地方法栈**，**系统产生一个线程或者各个线程之间切换工作的时候，负担比进程小得多**
* 高层面（线程的另一个层面）理解是，一个进程中不同的执行路线
* 《<u>Linux 内核设计与实现</u>》中解释了 **线程在 linux 中的实现，线程就是一个普通的进程**，开启一个线程就是开启了一个进程，只不过这个进程和当前进程共享资源（内存空间，全局数据）。

引入协程（JVM 线程和 OS 线程一对一）。。。巴拉巴拉

进程是程序的一次执行过程，是系统**运行**程序的基本单位。系统运行一个程序就是一个进程从创建，运行到消亡的过程

![image-20220810185625600](https://s2.loli.net/2022/08/10/5f6MvUdcLg1pWao.png)



### 僵尸进程/孤儿进程

* 僵尸进程：父进程产生子进程后，会维护子进程的一个 PCB 结构，子进程退出，由父进程释放

如果父进程没有释放，那么子进程称为一个僵尸进程

* 孤儿进程：子进程结束之前，父进程已经退出
  * 孤儿进程会成为 init 进程的孩子，由 1 号进程维护



### 程序如何开始执行？

CPU 读指令存PC

读数据存 Register

计算，回写，

下一条



### 线程如何调度

linux 线程调度器，操作系统



### 线程切换的概念是什么

> 线程切换本身需要消耗 CPU 资源，如果线程特别多，上下文切换所占的资源就超过了线程运行本身所占的资源。

context switch 

CPU 保存线程， 执行新线程，恢复现场，继续执行原线程的过程



![image-20220811092507486](https://s2.loli.net/2022/08/11/CuIyVTUAekJmhRs.png)



用户级别的线程和操作系统级别的线程对应关系是怎样的？

Java 与 内核级别的线程， 1：1

go 语言中是 m：n，并且 m 远远大于 n

考虑到线程切换对应的资源损耗，Java 中不能写特别多的线程，这样会将所有的资源都花在前程切换上，go 语言中则容量很大，在用户空间模拟了 cpu 的运行

<img src="https://s2.loli.net/2022/08/11/l8ANMC7IyLrWqat.png" alt="image-20220811104730328" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/08/11/V3qn8FgldzrC6TW.png" alt="image-20220811104715230" style="zoom:50%;" />



### 协（纤）程



![image-20220815173817222](https://s2.loli.net/2022/08/15/uz46rVvhbt8AOZP.png)

在 Java 中开启线程需要向内核申请，**JVM 中的线程和内核中线程是一对一的**，由操作系统调度，而且我们知道一个操作系统能够开启的线程是有限的。

而协程的优势在于**跑在用户态**，完全由 JVM 自己控制，自己切换，不需要和内核打交道，创建协程也不需要操作系统产生一个对应的线程，JVM中一个线程可以对应多个协程，**协程本身拥有自己的上下文栈**，在用户态就完成完整的业务逻辑。

因此就**节省了内核切换的开销，加锁解锁的开销**。

最后提一点就是，操作系统起一个线程大概需要 1M 空间，创建协程大概需要 4K.

目前支持协程的语言： kotlin，scala，go，python 。。。。java(open jdk loom) 利用 quaser 库，不成熟，有 bug



**协程 VS 线程池**

* 并发量高，首选协程。（起线程的代价高，需要经过内核）
* 很短的计算任务，不需要和内核打交道





#### 定义

* 协程，一种**用户态**的**轻量级**线程，协程的调度完全由用户控制。**协程拥有自己的寄存器和上下文栈**。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快

  * 我们把要写的代码、逻辑 交给 CPU 运算，这些运算单位被绑定到一个线程上面，然后线程有 id，通过这个 id 可以找到堆栈、寄存器信息，<u>整个程序的上下文在线程里面</u>，计算机分用户态和内核态，**Java 线程和 操作系统的线程是一对一的**，<u>我们把用户态的东西交给内核态，之后就不归我们控制了，线程一直在跑，直到中间出现异常，或者跑结束</u>
  * 但是协程，我们可以自己控制，暂停，继续运行 等等
  * 轻量级，轻在哪？ **内核切换的开销，加锁解锁的开销**
  * 协程最重要的一个特点，就是可以暂停

* 用途：在传统的 J2EE 系统中都是基于每个请求占用一个线程去完成完整的业务逻辑，所以系统的吞吐能力取决于每个线程操作耗时。如果遇到很耗时的 IO 行为，则整个系统吞吐量下降，因为这个时候线程一直处于阻塞状态，如果线程很多的时候，会造成很多线程处于空闲，造成了资源应用不彻底

  

<img src="https://s2.loli.net/2022/08/13/tHF8ql16Xjy9WBb.png" alt="image-20220813192114862" style="zoom:50%;" />



#### 信息交换方式

> 不要以共享内存的方式通信，相反，要通过通信来共享内存

传统并发模型：

* 共享内存，通过锁来访问共享数据

---

**思考：**

* 我们为什么要加锁？

因为整个计算过程是操作系统调度的，我们不知道这段代码在什么时间执行。

-> 如果整个过程由我们自己控制，那么就不需要加锁了

* 为什么需要上下文切换

因为 cpu 资源是有限的，需要轮流使用



#### 协程和线程比较



![image-20220813192915026](https://s2.loli.net/2022/08/13/FEvBoQyLnuDqp17.png)



## 线程的状态

* 新建状态 ： new 一个线程，还没有 start
* 运行状态（就绪和运行）：调用线程的 start 方法
  * 就绪： 调用了 start 方法，cpu 还没有分配时间片
  * 运行：调用了 start 方法，cpu 正在调度
* 阻塞状态：当竞争 syn 锁，没拿到，线程挂起
* 等待状态： join，wait，park 方法
* 超时等待状态
  * 区别于`WAITING`，它可以在**指定的时间**自行返回

* 死亡状态：run 方法结束，或者在 run 方法中抛出异常



## 线程池核心参数

直接使用 Excutors 构建会造成堆线程池控制力度很差



```Java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) 
```



### 合理分配线程池大小

要根据业务类型来决定：

* CPU 密集型，更多的 CPU 在做计算，一直在工作，线程数少一点，一般分配 CPU 数量 + 1
* IO 密集型，线程数多一点，CPU 内核数 * 2
* 混合型：将 cpu 密集型 和 IO 密集型 的操作分成两个线程池去执行



## CAS 的实现

号称无锁

<img src="https://s2.loli.net/2022/08/11/6rylb7hPkvWQ1xU.png" alt="image-20220811104648756" style="zoom: 67%;" />



不需要经过操作系统调度，在用户态就可以实现

在没有锁的情况下，在多线程访问的时候，保证多个线程一致性的对一个值的更新



### CAS 修改值时候的原子性如何保证？

* native 方法，C++ 实现的

* C++ 里面:  Atomic  ::  cmpxchg
* Atomic 类 x86 linux 上的实现 ，汇编语言，两条指令 lock_if_mp 以及 cmpxchg
  * mp 的意思是 muti - procrssors，多核处理器的时候上锁
  * lock 的意思是 在执行后面这条指令的时候把总线锁住
  * 几乎所有 cpu 都支持 lock cmpxchg

最终实现：

```
lock cmpxchg 指令
```

cmpxchg 本身没有原子性，原子性体现在 lock

硬件：

lock 指令在执行后面指令的时候锁定一个北桥信号

<img src="https://s2.loli.net/2022/08/11/oS7mPYJcCaEp4Wk.png" alt="image-20220811104630076" style="zoom:50%;" />

### ABA 问题

* 加版本号

### 资源消耗，占用 cpu

### 只能保证一个数据的安全，不能保证一段代码

## 对象在内存中的内存布局

![img](https://s2.loli.net/2022/08/10/DQHTNpBvghwm7Y4.png)





### Object o = new Object() 在内存中占了多少个字节

>  **Object 16字节**

jvm 本身默认开启了 class pointer 的压缩，于是由如下过程。

markword + class pointer + instance data + padding

对象头（markword + class pointer）： 12字节

*  markword： 8 字节
*  class pointer ： 4 字节 (默认经过压缩)
*  instance data: 空的（object 没有成员变量）
*  padding： 补到 8 的倍数， 4 字节

padding 当整体字节数不能被 8 整除的时候，进行填补

如下所示

| OFFSET | SIZE | DESCRIPTION                                     |
| ------ | ---- | ----------------------------------------------- |
| 0      | 4    | object header (markword)                        |
| 4      | 4    | object header (markword)                        |
| 8      | 4    | object header (class pointer)                   |
| 12     | 4    | loss due to the next object alignment (padding) |

> 注意一个小坑，Object o 开启了一个引用， 20个字节
>
> 另外，如果 Jvm 不开启  class pointer 压缩，那么 class pointer 占用 **8** 个字节，加上 markword 的 8 个字节，总共也是 16 个



**如果添加成员变量呢？**

例如： User{

​	int id;

​	String name;

}

markword ：8 字节

class pointer:  4 字节

instance data:   8 字节    （integer 4 字节 + String 引用 4 字节）  

padding : 4 字节 (填充为 8 的倍数)

总共： 24 字节



## 锁的概念

## 上锁、锁升级的过程

![image-20220811104552219](https://s2.loli.net/2022/08/11/dYlWAJ1eUODKNnI.png)



new(刚刚 new 出来，没有锁的状态) - 偏向锁 - 轻量级锁(自旋锁) - 重量级锁

synchronized 优化的过程和 markword 息息相关

用 markword 中最低的三位代表锁状态，其中 1 位是偏向锁位， 两位 是普通锁位置

注意： markword 中记录了哪些信息？ 锁信息以及GC

**<u>上锁：修改 markword</u>**

* **默认 synchoronized(0)**
  * 00 轻量级锁
  * 默认情况，偏向锁有个时延，默认是 4 秒
  * 因为 JVM 虚拟机自己有一些默认启动的线程，里面有好多 sync 代码，这些 sync 代码启动时就直到肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级，消耗系统资源
* **如果有线程上锁**
  * 上偏向锁（严格意义上来讲不是锁），只是 将 markword 中的**线程 id** 改为自己的线程 id （指针，JavaThread 54位），不用抢，这把锁就偏向于第一个线程
  * 偏向锁不可重偏向，批量偏向，批量撤销
  * markword 上记录着当前线程的指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否为同一个
  * 偏向锁，加锁的第一个线程， hashCode 备份在线程栈上，线程销毁，锁降级为无锁
  * 偏向锁存在的意义：类似于 Vector ， HashTable，StringBuffer 这些类有一个特点，方法上都写了 sync，但是根据调查，大部分情况下只有一个线程在运行他们，因此，**每当线程来的时候就进行锁竞争**，效率太低
* **如果有线程竞争**
  * 撤销偏向锁，升级轻量级锁
  * 线程在自己的线程栈生成 LockRecord，用 CAS 操作将 markword 设置位指向自己线程的 LR 指针，设置成功者得到锁( 62 位 LockRecord 指针)
  * JDL 1.4.2 中引入， JDK 6 之后默认开启，并且引入了适应性自旋锁，由JVM 自己控制
* **如果竞争加剧**
  * 竞争加剧： 超过 10 次 自旋，或者自旋线程超过 CPU 核数的一半
  * 升级重量级锁：向操作系统申请资源， linux mutex， CPU 从 3级-0级 系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间。( 62 位 指向互斥量  mutex 重量级锁的指针)
  * 解释一下用户态和内核态：操作系统中将程序的执行状态分为用户态和内核态，内核态指内核和硬件打交道，一些操作只有它能执行，想要执行就要切换到内核态，我们不能直接操作硬件

（以上是 JDK 11，打开就是偏向锁，JDK 8 默认对象头是无锁）

## 轻量级锁和重量级锁的区别

轻量级锁是运行在用户态的，不需要经过内核的申请和批准，因此效率特别高。能在用户态解决的就不需要经过内核态，但是 CAS 自旋锁是一个循环，是不断需要消耗 CPU 的，如果竞争特别激烈，CPU就被占满了

重量级锁中，没有抢到锁的线程会进入一个队列 EntrySet，变为阻塞状态，不需要消耗 CPU ，由操作系统决定阻塞的线程什么时候执行

#### markword 记录了哪些信息

注意：上锁就是修改 markword 的过程

* 锁信息
* GC 信息
* hashCode

![image-20220810205259906](https://s2.loli.net/2022/08/10/4NeqU6wzXigfJ3c.png)

## 锁降级

锁降级在某些特定的情况下会发生，但是这种特定的情况下，也就是 GC 的时候，这把锁已经不被任何线程访问了，会发生锁降级。

但是这个过程发生在 GC ，除了 GC 没有任何线程访问

可以简单认为不存在



## 锁消除

StringBuffer 是线程安全的，因为它的关键方法都是被 sync 修饰过的

但是在一些情况下， sb 的引用只在一个方法中使用，不可能被其他线程引用（局部变量，栈私有），因此 sb 是不可能共享的资源， JVM 会自动消除 sb 对象内部的锁

```java
public void add(){
    sb.append().append().append().... // StringBuffer 在这个过程会不停的加锁解锁
}
```





## 锁粗化

JVM 会检测到这样一连串的操作都是对同一个对象加锁，此时 JVM 就会将加锁的范围粗化到这一连串操作的外部，比如 while 循环体外，使得这一连串操作只需要加锁一次。



## sync

jdk 1.0   -   jdk 1.2  ： sync 直接使用重量级锁，操作系统接管对应线程，反馈给 JVM，效率非常低

jdk 1.5 之后 诞生了 JUC 包

不能用常量，不能用基础数据类型 String Integer Long 等等



## Atomic

底层用到的就是自旋锁，CAS 保证线程安全

由于某些特别常见的操作总是需要加锁，加锁的情况特别多 

Java 内部提供了一些类，内部就带锁，不是重量级锁，CAS 锁

凡是 Atomic 开头的，都是用 CAS 实现的

**CAS 是 cpu 原语支持，中间过程不可被打断！**

Atomic 就是原子性的意思，即**能够保证在高并发的情况下只有一个线程能够访问这个属性值。**

## sync 的层级实现

* java 代码层级： 就是在代码中加入 sync
* java 代码编译成字节码：  monitorenter 指令进入锁状态, 退出的时候叫 monitorexit
* jvm 执行的过程中自动升级： 偏向锁 -> 轻量级(自旋)锁 -> 重量级锁
* lock comxchg





## 重入锁

Java 大多数的锁都是重入锁

JUC 实现的不可重入锁只有一种









## 超线程

一个 ALU 对应多个 PC|Register

所谓的四核八线程

![image-20220810220918843](https://s2.loli.net/2022/08/10/f4LPJexRjltAqVM.png)



## Cache line 缓存行对齐 伪共享

@Contentded 注解，缓存行填充

![image-20220810205318320](https://s2.loli.net/2022/08/10/BUY2svaSMLPhHpN.png)

cpu 读数据的时候，首先去缓存 L1 -> L2, -> 共享的 L3 ，之后去内存中读

cpu 在内存中读数据的时候，不会只读一个，而是读一块，这个一块就叫做 缓存行

cpu 层级的数据一致性，是以 cache line 为单位的

缓存行：

* 缓存行越大，局部性空间效率越高，但读取时间慢
* 缓存行越小，局部空间效率越低，但读取时间快
* 取一个折中值，目前多用 **64** 字节

**尽量让一个业务填满整个缓存行。 JDK 1.8 一般采用 @Contended 注解**

![image-20220810220855935](https://s2.loli.net/2022/08/10/PTCEenWtNUojQwX.png)



### MESI Cache 一致性协议

x86 cpu 也就是英特尔 cpu，用的是 mesi 协议保证缓存数据一致性

cpu 每个 cache line 标记四种状态

* modified
* exclusive
* shared
* invalid 失效

缓存锁实现之一：

* 有些无法被缓存的数据或者跨越多个缓存行的数据，依然必须使用总线锁

https://www.cnblogs.com/z00377750/p/9180644.html



## 乱序执行

cpu 的读等待同时执行指令执行



读指令的同时可以同时执行不影响的其他指令，而写的同时可以同时合并写

这样 cpu 的执行就是乱序的



必须使用 memory barrier 来做好指令排序

volatile 的底层就是这么实现的， windows 是 lock 指令



jvm 层级叫内存屏障，cpu 层级叫 lock 指令



## 系统底层如何保持数据一致性

* 如果一致性协议 MESI 能解决，就用 MESI
* 如果不能解决，就锁总线（直接给总线上锁）



## 系统底层如果保证有序性

* 内存屏障 sfence mfence ifence 等系统原语
* 锁总线



## 美团追魂七连问

单例模式：某个类的对象在内存中保证只有一份。构造方法私有化，类内部返回自己创建的类对象

![image-20220811091930663](https://s2.loli.net/2022/08/11/AewqWDvRbOKCrPF.png)

![image-20220811091908030](https://s2.loli.net/2022/08/11/Xm8UHxsgQv2JuBq.png)

### 关于 Object o = new Object()

* 请解释一下对象的创建过程？（半初始化状态）
* 加问 DCL 与 volatile 问题？（指令重排）
* 对象在内存中的存储布局
* 对象头具体包括什么
* 对象怎么定位
* 对象怎么分配？（栈上-线程本地-Eden-Old）
* Object o = new Object（） 在内存中占用多少字节
* 为什么 hotspot 不使用 c++ 对象来代表 java 对象
* Class 对象是在堆还是在方法区



---



![image-20220811091949976](https://s2.loli.net/2022/08/11/BQI582THJtCZkvu.png)



* new 指令 ，allocate，申请一块内存，**把一块确定的大小的内存从java堆中划分出来**，这个时候 m = 0
  *  a、指针碰撞（Bump the Pointer）：假如java堆中的内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配的内存就仅仅是把那个指针向空闲空间那边挪动一段与对象的大小相等的距离。
  * b、空闲列表（Free List）: 假如java虚拟机不是规整的，<u>已使用的内存和空闲的内存相互交错</u>，虚拟机就必须维护一个列表，记录上那些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新表上的实例。选择哪种分配方式由java堆是否规整决定，而java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。
  * 设置对象头
* invokespecial ，执行构造方法
* astore ： 我们的引用 t 和 m **建立关联**



* 那么**new 指令后，为什么一定要dup操作呢?**
* 因为java代码的new操作编译为[虚拟机](https://so.csdn.net/so/search?q=虚拟机&spm=1001.2101.3001.7020)指令后，虚拟机指令new在堆上分配了内存并在栈顶压入了指向这段内存的地址供任何下面的操作来调用，但是在这个操作数被程序员能访问的操作之前，虚拟机自己肯定要调用对象的 <init> 方法，也就是如果程序员做一个 Type a = new Type(); 其实要连续两次对栈顶的操作数进行操作。**其中一次是虚拟机内部自动调用的，另一次才是程序员的访问，例如给变量赋值，抛出异常等**。





DCL： Double Check Lock 双重检查

```
new # 这一步执行完，对象内存已经 new 出来，但是还没有初始化（默认值），这种状态成为半初始化
dup
invokespecial
astore_1
return
```

![image-20220811091832176](https://s2.loli.net/2022/08/11/lQYcoq7jCzGRMUr.png)



在创建对象的过程中发生了指令重排，还没有执行构造方法就建立了关联（**单线程下这样做是没有影响的**）

这时候又进来了一个线程，判断 instance 不等于空，将这个对象拿走了

即，半初始化状态

因此，必须要加 volatile，对这个对象的读写不可以重排序





**对象的定位方式**

句柄和直接指针

* 直接指针，引用 t 指向堆中的实例数据，实例数据中包含指向类型数据的指针
  * 优点：效率高
  * 缺点：每经过一次 GC 复制，就需要跟着改变
* 句柄，引用 t 指向一组指针，包括实例数据和类型数据
  * 优点：方便 GC， GC 复制的时候，里面的值不需要变

![image-20220811213619455](https://s2.loli.net/2022/08/11/lY4dQVPKXESbaH3.png)



**对象怎么分配**

* new 出来的对象**优先分配在栈上**，条件是 **大小较小** （JVM 调优的时候我们经常调整 -xss 参数，即栈帧大小，这样就允许有更多对象直接分配在栈上）且 **不存在逃逸**。
  * 直接分配在栈上的对象，会随着栈帧弹出自动销毁，**不需要 GC 介入**，因此效率很高
  * 不存在逃逸的意思是：只有当前栈帧使用到该对象，除此之外没有其他地方使用到这个对象
* 如果不能分配在栈上，判断这个对象是不是很大，如果是，分配在 老年代，之后通过 GC 回收
* 如果不是很大，分配在线程本地缓冲区（Thread Loca Allocation Buffer，TLAB），Eden 区分配。每个线程都有自己额外的小小的空间，优先往自己的 TLAB 分配
  * 经过一次 GC ，清除掉了，就被销毁
  * 如果没清除掉，从年轻代去 Survive 区，再经过垃圾回收，年龄够大区 Old，否则去另一个 Survive ，在此循环往复



![image-20220811215419259](https://s2.loli.net/2022/08/11/89aqMpJjV1AEhD5.png)



**为什么 hotspot 不使用 c++ 对象来代表 java 对象**

c++ 对象存在一个虚函数表，占用内存太大了



**Class 对象是在堆还是在方法区**

方法区、永久代、元空间的区别是：

* 方法区是接口，剩下两个是实现类

  * jdk 1.7 之前，方法区的实现叫永久代

  * 1.8 开始，方法区的实现叫 元空间

instanceClassOOP 对象，是一个 C++ 对象，在方法区，指回到堆空间。

* **为什么扔在堆里，方便我们拿出来做反射用**

* 各种各样代理对象太多的时候，方法区会出现 OOM

![image-20220811215931586](https://s2.loli.net/2022/08/11/6bgKyd1NfG7JFCj.png)



**Object o = new Object() 在内存中占了多少个字节**

>  **Object 16字节**

jvm 本身默认开启了 class pointer 的压缩，于是由如下过程。

markword + class pointer + instance data + padding

对象头（markword + class pointer）： 12字节

*  markword： 8 字节
*  class pointer ： 4 字节 (默认经过压缩)
*  instance data: 空的（object 没有成员变量）
*  padding： 补到 8 的倍数， 4 字节

padding 当整体字节数不能被 8 整除的时候，进行填补

如下所示

| OFFSET | SIZE | DESCRIPTION                                     |
| ------ | ---- | ----------------------------------------------- |
| 0      | 4    | object header (markword)                        |
| 4      | 4    | object header (markword)                        |
| 8      | 4    | object header (class pointer)                   |
| 12     | 4    | loss due to the next object alignment (padding) |

> 注意一个小坑，Object o 开启了一个引用， 20个字节
>
> 另外，如果 Jvm 不开启  class pointer 压缩，那么 class pointer 占用 **8** 个字节，加上 markword 的 8 个字节，总共也是 16 个



**如果添加成员变量呢？**

例如： User{

​	int id;

​	String name;

}

markword ：8 字节

class pointer:  4 字节

instance data:   8 字节    （integer 4 字节 + String 引用 4 字节）  

padding : 4 字节 (填充为 8 的倍数)

总共： 24 字节



## JVM 的内存屏障

屏障两边的指令不能重排，保障有序！

![image-20220811091745436](https://s2.loli.net/2022/08/11/EkpjQtJz8nN2uwh.png)

## Volatile 如何解决指令重排序

> 应用场景： 单例模式懒加载 + ConcurrentHashMap 中非常重要的变量 sizeCtl



cpu 会在保证 happens-before 的前提下，对指令进行重新排序，从而提高效率



volatie 的语义有两个，分别是： 线程间可见，禁止重排序

但是需要注意，volatile **并不能保证原子性**

依赖 CPU 的缓存一致性协议 MESI

* 1.代码中加了 volatile
* 2.字节码中只是加了一个标记 ACC_VOLATILE
* 3.交给虚拟机实现，当虚拟机看到这种字节码，进行相应处理（由 JVM 加屏障），见下图
* 4.hotspot 实现（不同版本虚拟机有不同实现），**在两条指令中间追加 lock 指令**



既然有 sfence mfence ifence 等 cpu 底层就能支持的原语， hotspot 为什么还要使用 **lock** 指令？

-> 这是从可移植性的角度考虑的，某些 cpu 可能不支持 sfence, mfence 这种原语，但大多数都支持hotspot

* lfence 读串行化
  sfence 写串行化
  mfence 读写都串行化

![image-20220811091703436](https://s2.loli.net/2022/08/11/YXGgQ3uNRn4oyI6.png)

> 不管 Volatile 还是 sync，底层都是 lock 指令
>
> lock 叫锁总线，其他 cpu 都无法访问 
>
> 
>
> lock 用于在多处理器中执行指令的时候对**共享内存的独占使用**
>
> 它的作用是能够将**当前处理器对应缓存的内容刷新到内存，并使其他处理器对应的缓存失效**
>
> 另外还提供了**有序的指令无法越过这个屏障的作用**



![image-20220811091725068](https://s2.loli.net/2022/08/11/enWdqOw7Tm1Fiy8.png)

* addl 指令没有作用，因为 lock 指令规定，后面必须跟一条指令，在执行这条指令的时候锁总线

---



## 强软弱虚 - Java 中的引用类型

不同引用的区别主要体现在，**对象不同的可达性状态** 以及 **垃圾收集** 的影响

* 强引用，能 get 到， GC 不会回收，除非引用指向 Null。
* 软引用，能 get 到，GC 不会回收，但是内存不足，GC 会回收，非常适合缓存使用
* 弱引用，能 get 到，但只要 GC ，就回收，**一次性**
* 虚引用，get 不到，只有一个作用，就是管理堆外内存。当虚引用被回收，会加到一个队列里，之后根据这个队列去清理堆外内存。DirectByteBuffer
  * 创建虚引用的时候，参数需要传入一个队列
  * 当虚引用被干掉，会通知你，通知的方式就是，向队列中扔进去一个值
  * 我们可以拿着这个值，清除堆外内存


![image-20220811091634128](https://s2.loli.net/2022/08/11/egIABcMuDykJXpR.png)



![image-20220811091608056](https://s2.loli.net/2022/08/11/3sfzBUpntVAM9hb.png)



![image-20220811091550594](https://s2.loli.net/2022/08/11/l7PG8rtkhHb9ajD.png)



---





## ThreadLocal

本质上就是一个 Map，可以将一个数据和本地线程绑定在一起

![image-20220812211449068](https://s2.loli.net/2022/08/12/NFZRS7i3Uxp6rgm.png)

![image-20220812212617495](https://s2.loli.net/2022/08/12/L2x8uzNJFqWRZed.png)





每个线程自己独立拥有，线程存在，这个变量就一直存在

```Java
// Thread 类中的成员变量
ThreadLocal.ThreadLocalMap threadLocals = null;
```



联系 Spring 中的 Transaction 事务操作

需要保证 m1 m2 在同一个线程中，那么他们的 ThreadLocal 就是一样的，拿到的数据库连接也是一样的

实现方式，通过 thread 拿到 **ThreadLocalMap**<ThreadLocal,value>，通过 ThreadLocalMap 进行操作

![image-20220811091514822](https://s2.loli.net/2022/08/11/cWBbIEOQrUK5XZx.png)

![img](https://s2.loli.net/2022/08/11/G6DnhNI4MZXdL8Q.png)



### 内存泄漏问题

**使用 ThreadLocal 最后记得 remove，避免内存泄漏**

![image-20220811091334400](https://s2.loli.net/2022/08/11/w2fg4jZ9yzcmHYX.png)

![img](https://s2.loli.net/2022/08/11/PDZXEOLYIrceNvp.png)

## 内存管理

现在的内存管理系统： 虚拟地址 + 分页装入 + 软硬件结合 + 寻址

时间换空间

解决内存撑爆问题：分块装入页框中（内存页 4K 标准页）

局部性原理：

* 时间局部性：指令旁边的指令很快执行
* 空间局部性：数据旁边的数据很快用到



内存满了，进行交换分区

* 分页（解决内存不够用）
  * 内存中分成固定大小的页框，4k，把程序（硬盘）上分成 4k 大小的块**，用到哪一块，加载哪一块**。加载的过程中，如果内存已满，新加载的块会把最不常用的一块放到 swap 分区，把最新的一块加载进来，这个就是 LRU 方法

* **虚拟内存**（解决程序间相互打扰）

  * 为了保证互不影响，让进程工作在虚拟空间，**程序中用到的空间地址不再是直接的物理地址**，而是虚拟的地址，这样，A 进程永远不可能访问到 B 进程的空间

  * 虚拟空间多大呢？ 寻址空间 - 64 为系统， 2^64 ，比物理空间大很多

  * 站在虚拟的角度，进程独享整个系统  + CPU
  * 内存映射： 
    * 偏移量 + 段的基地址 = 线性地址（虚拟空间）
    * 线性地址通过 OS + MMU （cpu 中的硬件 Memory Management Unit）

![image-20220815195905876](https://s2.loli.net/2022/08/15/hxMv14DVKPbS5cp.png)

![image-20220815201425872](https://s2.loli.net/2022/08/15/JqcxwMd6K4WUA91.png)

## 为什么要使用虚拟内存

* 隔离应用程序
  * 每个应用程序都认为自己有连续可用的内存
  * 突破物理内存的限制
  * 应用程序不需要考虑物理程序是否够用，是否能够分配等底层问题
* 安全，保护物理内存，不被恶意程序访问



## ConcurrentHashMap

JDK 1.8

* 在没有 hash 冲突的时候，以 CAS 的方式尝试插入到数组中
* 如果有 hash 冲突，这个时候会将当前数组索引位置锁住，以 syn 的形式挂到链表下面
* 如果数组长度达到了最开始长度的 0.75 （负载因子），就要将数组长度扩大 2 倍。避免链表过长，查询效率降低

ConcurrentHashMap 并发扩容，如何保证安全？

在计算 Node 中 key 的 hash 值时，会特意的将 hash 值正常情况的数值定义为正数

负数有特殊含义，如果 hash 值为 -1 ，代表当前结点正在扩容

ConcurrentHashMap 会在扩容时，每次将老数组中的数据 table.size - 1 ~ table.size - 16 索引的位置移动，然后再移动其他。如果有线程在插入数据时，发现正在扩容，找还没有倍迁移数据的索引位置，帮助最开始扩容的线程进行扩容

每一个迁移完毕的数据，都会加上标识，标识扩容完毕，放上一个 forwardingNode 结点，代表扩容完毕，而且在扩容时，不会应用 ConcurrentHashMap 的遍历，查询和添加（发现扩容，会帮忙）



为什么，线程扩容时，会使用 sizeCtl 记录现在扩容时的线程数量，1 个线程扩容，低位数值为2，2个线程扩容，低位是 3 ？

* sizeCtl 为 -1，**代表正在初始化**， -N 表示正在扩容

  





## ReentrantLock

Java 中提供的锁： synchronized , lock 锁

ReentrantLock 就是一个互斥锁，可以让多线程执行期间，只有一个线程在执行指定的一段代码

其实 Lock 接口至今一直被大众所喜爱，**主要不在于说它的性能方面，而是它更加具备有灵活性**。

- 支持非阻塞方式获取锁；
  -  tryLock：获取锁时如果失败了，则不会继续等待，而是会立马返回一个布尔状态值。这一点相比于 synchronized 关键字而言要灵活些，synchronized 关键字在抢夺锁失败之后，只能够进入一个等待队列中，而 tryLock 可以迅速告知调用方结果，从而进入对应的程序分支中进行处理。

- 支持锁超时机制
  - Lock 支持锁超时机制，这个功能要比单纯的 lock 函数更加强大，当获取锁超过一定时间，便会主动退出等待

- 支持可中断方式获取锁。
  - 当线程在执行该函数之后会进入等待状态，在等待的过程中是可以通过 Thread.interupt 函数去进行中断的。
  - `lockInterruptibly` 允许在等待时，由其它线程调用等待线程的 Thread.interrupt 方法来中断等待线程的等待，这一点和 Lock.lock 函数以及 synchronized 关键字是有所不同的。











### 区别 Sync

* 底层加锁使用 CAS ，Sync 锁升级
* tryLock 尝试获取，获取不到就算了，Sync 自旋或者阻塞线程
* lockinterupptibly 中断
* 公平锁和非公平锁，Sync 没有公平锁



### Lock 方法

在进入到 lock 方法后，发现内部调用了 sync.lock 方法。存在两种方法实现

* FairSync ： 公平锁

  * 线程会一个一个**排队**获取锁资源(先查看是否有人排队)，中间不允许插队
  * 如果需要使用公平锁， 在构造方法中传入 true
  * 代码层面，**直接调用 acquire 方法**

* NonFairSync ： 非公平锁 (构造方法中，默认是非公平锁  sync = new NonFair() )

  * 线程都会在执行 lock 方法时，先**尝试获取资源**，获取不到再排队
  * 更推荐非公平锁，效率更高
  * 代码层面，**先 CAS 竞争一下，else 竞争不到，调用 acquire**

  

---



> ReentrantLock   ->  sync   -> AQS

### AQS

AbstractQueueSynchronized 类， AQS 内部维护着一个队列

* AQS 内部维护着一个队列（双向链表） + 三个核心属性(head + tail + state)

* 内部有个 Node 对象，包括 prev 和 next 成员变量，还有 head tail，实际上是一个双向链表
* Node 内部的成员变量 state，获取锁的过程就是使用 CAS 的方式更改 state
* 当线程尝试获取锁，发现 state 为 1，那么就被放到 node 对象中排队(双向链表)



![image-20220811155806992](https://s2.loli.net/2022/08/11/ol3AbgcZOKnpJMq.png)

---



### Lock 方法源码



![image-20220811160834057](https://s2.loli.net/2022/08/11/1WjCVfld9D8Josp.png)

---



### Acquire



![image-20220811183617383](https://s2.loli.net/2022/08/11/Lu9evt4k7jJEhmx.png)



---



### tryAcquire

非公平锁

![image-20220811191900034](https://s2.loli.net/2022/08/11/OresIxHtvB1g3EU.png)

公平锁

![image-20220811192337986](https://s2.loli.net/2022/08/11/ykbI3Kpjnv8lEBC.png)



* 公平锁和非公平锁 tryAcquire方法的唯一区别就是，当判断 state 为 0 后，
* 公平锁首先查看是否有线程排队，如果有直接返回 false，如果没有线程排队，执行 cas 尝试获取锁资源
* 非公平锁直接使用 CAS 竞争锁资源



###  addWaiter 方法

addWaiter  实际上位于 ReetrantLock  内部类 sync 的父类 AQS

在线程执行 tryAcquire 方法没有获取到锁资源，会返回 false ， 在加上 if 中的操作，会执行 && 后面的方法，也就是 , 将当前线程封装到 node，放入队列(双向链表)中排队

```Java
public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
```



![image-20220811195324292](https://s2.loli.net/2022/08/11/la1kNt7JhFLCzcm.png)

![image-20220811195340161](https://s2.loli.net/2022/08/11/CIXfirOjSk46zAb.png)



###  acquireQueue 方法

首先查看当前 node 是否排在队列的第一个位置

* 第一个位置，再次执行 tryAcquire 方法竞争锁资源
* 否则，尝试将当前线程挂起，最终排在有效结点（状态为 SIGNAL）后，才会将当前线程挂起



![image-20220811201810450](https://s2.loli.net/2022/08/11/ZVz4PcKw2rDh7MU.png)



![image-20220811202616555](https://s2.loli.net/2022/08/11/VNKahug5PGD9T2v.png)





### unlock 方法

* 不分为公平、非公平
* 都是执行 sync 的 release 方法
* 将 status从 大于 0 的数值改为 0 即为释放成功（可重入，因此 status可能大于 1）
* unlock 方法 涉及到将 AQS 队列中阻塞的线程（park）进行唤醒（unpark）



### release 方法

需要注意一点，成功释放锁（status 变为0）后，需要 unpark 队列头的线程

![image-20220811203944485](https://s2.loli.net/2022/08/11/muXkbH4nKOgCBjM.png)





## ForkJoin

从 JDK7 版本开始，ForkJoin 线程池开始对各个开发者开放。

这款线程池的特别之处在于，它不单单执行任务，还会将一个大的任务拆解为多个小任务，再执行。

在  ForkJoin 线程池组件中，充分体现了先拆解，后合并的设计思想。



![image.png](../Pic/639c68d9400a4059afc60826a23ba9fftplv-k3u1fbpfcp-zoom-in-crop-mark3024000.awebp)

在 ForkJoin 的内部，每个请求的任务都会通过决策被放入到某条队列中，接着会有一批提前准备好的线程从各个队列中去获取任务。**因此，ForkJoin 利用了多线程 + 多队列的方法来提升任务的处理速度。**

---

此外，当 ForkJoinPool 中的线程处于空闲的时候，它们会自觉去扫描其他的任务队列，查看是否有可执行的任务。如果发现有，则会窃取其他队列上的任务。

优点：充分利用线程进行并行计算

缺点：消耗了更多的系统资源，某种情况下会存在竞争





## 如何优雅终止线程

### suspend 方法

suspend 翻译过来是暂停的意思，在 Thread 类的内部，也确实存在一个叫做 suspend 的方法，这个方法在执行的时候，可以将一个执行任务到一半的线程进行暂停，如果要恢复的话，调用 resume 方法即可。

suspend / resume 被废弃了

**这是因为当线程调用了suspend操作之后，线程虽然暂停了，但是如果该线程曾经持有过锁并且也未曾主动释放过锁的话，那么这个处于暂停状态的线程就会一直持有锁，从而可能会导致其他希望获取锁的线程一直处于等待状态。**



### stop方法

在 Thread 类中，提供了一个叫做 stop 的函数，这个方法有点类似于 Linux 操作系统中的 kill 指令，它的本质是直接终止线程，如果线程中持有某个锁对象，还会强制将该锁释放，从而可能导致该锁所保护的临界区缺少同步安全性。

废弃。

转账收款，数据一致性问题。

### interrupt 方法

这个函数的名字翻译过来是中断的意思，但是它实际上并不是真正中断，只是将指定线程的状态调整为了中断类型。

以看到` interrupted`方法在进行中断的时候会抛出一个 `java.lang.InterruptedException `的异常，**但是被打断的线程在抛出异常之后依旧会正常执行任务**

采用 interrupted 函数并不能真正地将线程中断，只能告知线程，目前需要进入中断状态，然后修改线程的状态为停止状态，但是接下来的处理流程得由线程自己去决定。

interrupt() 并不能真正中断线程，需要被调用的线程自己进行配合才行。一个线程如果有被中断的需求，那么就可以这样做：在正常运行任务时，通过调用 **isInterrupted** ****方法去检查本线程的中断标志位，如果线程被设置了中断标志，就自行停止线程。

```Java
static class TestInterruptedStop implements Runnable {

    @Override
    public void run() {
        synchronized (this) {
            //如果当前线程被中断，这里需要主动退出
            while (!Thread.currentThread().isInterrupted()) {
            }
            System.out.println("end");
        }
    }
}
```



### 线程池的关闭

JDK 的线程池内部提供了两个关闭方法，shutdownNow 和 shuwdown 方法。

shutdownNow 方法的解释是：线程池拒接收新提交的任务，同时**立马**关闭线程池，线程池里的任务不再执行。

shutdown 方法的解释是：线程池拒接收新提交的任务，同时等待线程池里的**任务执行完毕后**关闭线程池。

![image-20220921155210312](../Pic/image-20220921155210312.png)



## ThreadPoolExecutor

### 线程池中核心属性 ctl

![image-20220812200508870](https://s2.loli.net/2022/08/12/UDFb7qnJoeIstd5.png)



### 线程池的状态变换

![image-20220812201800573](https://s2.loli.net/2022/08/12/rNG1enJSsdoijfy.png)



![image-20220812201736661](https://s2.loli.net/2022/08/12/DUusBRqzy5cCX7n.png)





### execute 方法

* 通过 execute 方法，可以查看线程池的整体执行流程，以及一些避免并发问题的判断
* 为什么线程池会添加一个空任务的非核心线程到线程池

![image-20220812194428696](https://s2.loli.net/2022/08/12/A1KaxnXOpfhsCrE.png)



![image-20220812203721175](https://s2.loli.net/2022/08/12/9L4WJgua5ET7NMS.png)





### addWorker 方法

```Java
// 线程池中添加 worker
private boolean addWorker(Runnable firstTask, boolean core) {
        // 对线程池状态的判断，以及对工作线程数量的判断
        // 外层 for 循环的标识
        retry:
        for (;;) {
            int c = ctl.get();
            int rs = runStateOf(c);

            // Check if queue empty only if necessary.
            if (rs >= SHUTDOWN && ! (rs == SHUTDOWN && firstTask == null && ! workQueue.isEmpty()))
                return false;

            for (;;) {
                int wc = workerCountOf(c);
                if (wc >= CAPACITY ||
                    wc >= (core ? corePoolSize : maximumPoolSize))
                    return false;
                if (compareAndIncrementWorkerCount(c))
                    break retry;
                c = ctl.get();  // Re-read ctl
                if (runStateOf(c) != rs)
                    continue retry;
                // else CAS failed due to workerCount change; retry inner loop
            }
        }

        // 添加工作线程并启动
        boolean workerStarted = false;
        boolean workerAdded = false;
        Worker w = null;
        try {
            w = new Worker(firstTask);
            final Thread t = w.thread;
            if (t != null) {
                final ReentrantLock mainLock = this.mainLock;
                mainLock.lock();
                try {
                    // Recheck while holding lock.
                    // Back out on ThreadFactory failure or if
                    // shut down before lock acquired.
                    int rs = runStateOf(ctl.get());

                    if (rs < SHUTDOWN ||
                        (rs == SHUTDOWN && firstTask == null)) {
                        if (t.isAlive()) // precheck that t is startable
                            throw new IllegalThreadStateException();
                        workers.add(w);
                        int s = workers.size();
                        if (s > largestPoolSize)
                            largestPoolSize = s;
                        workerAdded = true;
                    }
                } finally {
                    mainLock.unlock();
                }
                if (workerAdded) {
                    t.start();
                    workerStarted = true;
                }
            }
        } finally {
            if (! workerStarted)
                addWorkerFailed(w);
        }
        return workerStarted;
    }
```

























































