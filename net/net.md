# 网络与 IO



## HTTP v.s. HTTPS

### HTTP 协议

全称超文本传输协议。超文本，也就是网络上的包括文本在内的各式各样的消息，具体来说，主要是来规范浏览器和服务器端的行为的。

HTTP 是一个无状态协议，也就是说，服务器不维护任何有关客户端过去所发请求的消息。

**HTTP 通信过程**

HTTP 是应用层协议，以 TCP 作为底层协议，默认端口 80.主要过程如下

* 服务器在 80 端口等待客户端的请求
* 浏览器发起到服务器的 TCP 连接 （创建 Socket）
* 服务器接收来自浏览器的 TCP 连接
* 浏览器 （HTTP 客户端） 与 Web 服务器（HTTP 服务器）交换 HTTP 消息
* 关闭 TCP 连接



优点：扩展性强，速度快，跨平台支持性好

---

### HTTPS 协议

（Hyper Text Transfer Protocol Secure）

> HTTPS 之所以能达到较高的安全性要求，就是结合了 SSL/TLS 和 TCP 协议，**对通信数据进行加密，解决了 HTTP 数据透明的问题。**

是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并**额外使用 SSL/TLS 协议用作加密和安全认证**。**默认端口号是 443.**

HTTPS 协议中，SSL 通道通常使用基于密钥的加密算法，密钥长度通常是 40 比特或 128 比特。



优点： 保密性好，信任度高



### SSL 和 TLS 的区别？

**SSL 和 TLS 没有太大的区别。**

SSL 指**安全套接字协议**（Secure Sockets Layer），首次发布与 1996 年。SSL 的首次发布其实已经是他的 3.0 版本，SSL 1.0 从未面世，SSL 2.0 则具有较大的缺陷（DROWN 缺陷——Decrypting RSA with Obsolete and Weakened eNcryption）。很快，在 1999 年，SSL 3.0 进一步升级，**新版本被命名为 TLS 1.0**。<u>因此，TLS 是基于 SSL 之上的，但由于习惯叫法，通常把 HTTPS 中的核心加密协议混成为 SSL/TLS。</u>



**工作原理**

SSL/TLS  的核心要素是非对称加密。

采用两个密钥：公钥和私钥

在通信时，私钥由解密者保存，公钥由任何一个想与解密者通信的发送者保存



### 数字签名技术

数字签名，是 CA 在给服务器颁发证书时，使用散列+加密的组合技术，在证书上盖个章，以此来提供验伪的功能。



![image-20220830201328369](../Pic/image-20220830201328369.png)

### 总结：

- **端口号** ：HTTP 默认是 80，HTTPS 默认是 443。
- **URL 前缀** ：HTTP 的 URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`。
- **安全性和资源消耗** 
  - HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。
  - HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。<u>所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。</u>
  - 所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。

![img](../Pic/20201209163352.png)

## HTTP 1.0 v.s. HTTP 1.1

* **连接方式**
  * HTTP 1.0 默认使用短连接，每请求每连接， HTTP 1.1 默认使用长连接
  * *有必要说明的是，HTTP/1.0仍提供了长连接选项，即在请求头中加入`Connection: Keep-alive`。同样的，在HTTP/1.1中，如果不希望使用长连接选项，也可以在请求头中加入`Connection: close`，这样会通知服务器端：“我不需要长连接，连接成功后即可关闭”。*
* **状态响应码**
  * HTTP 1.1 中新加入了大量的状态码，光是错误响应状态码就新增了 24 种
* **Host 头处理**：
  * HTTP 1.0是没有host域的，HTTP1.1才支持这个参数。
* **缓存处理**

  * HTTP 1.0 中主要使用 header 里的 if-Modified-Since, Expires 来作为缓存判断的标准
  * HTTP 1.1 则引入了更多的缓存控制策略。Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
* **带宽优化以及网络连接的使用**
  * HTTP 1.0 中，存在一些浪费带宽的现象。例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持**断点续传**功能
  * HTTP 1.1 中则在请求头引入了 range 头域，它允许只请求资源的某个部分，返回码是 206.
  * 这样就方便了开发者自由选择，充分利用带宽和连接
*  **压缩**

  * 许多格式的数据在传输时都会做预压缩处理。数据的压缩可以大幅优化带宽的利用。然而，HTTP/1.0对数据压缩的选项提供的不多，**不支持压缩细节的选择，也无法区分端到端（end-to-end）压缩或者是逐跳（hop-by-hop）压缩**。

  * HTTP/1.1则对**内容编码（content-codings）和传输编码（transfer-codings）做了区分。内容编码总是端到端的，传输编码总是逐跳的。**

  * HTTP/1.0包含了`Content-Encoding`头部，对消息进行端到端编码。HTTP/1.1加入了`Transfer-Encoding`头部，可以对消息进行逐跳传输编码。HTTP/1.1还加入了`Accept-Encoding`头部，是客户端用来指示他能处理什么样的内容编码。

> `100 (Continue)`——在请求大资源前的预热请求，
>
> `206 (Partial Content)`——范围请求的标识码，
>
> `409 (Conflict)`——请求与当前资源的规定冲突，
>
> `410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址

---



<img src="../Pic/image-20220829203139369.png" alt="image-20220829203139369" style="zoom: 80%;" />

---



我们知道，不同的域名通过A记录或者CNAME方式可以连接都同一个IP下，同一个IP也可以设置多个不同站点，那我访问不同的域名都转发到同一IP，怎么区分这些不同的站点呢，就是用的Host字段，如果服务器后台解析出Host但是服务器上找不到相应的站点，那么这个连接很可能会被丢弃，从而报错。



## HTTP 常见状态码

HTTP 状态码用于描述 HTTP 请求的结果

![image-20220829202234961](../Pic/image-20220829202234961.png)

https://javaguide.cn/cs-basics/network/http-status-codes.html



## 一个完整的HTTP请求过程

https://nyimac.gitee.io/2020/12/10/URL%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B5%81%E7%A8%8B/



HTTP事务=请求命令+响应结果

![img](../Pic/20170516223520198.png)

---

一次完整的请求过程：

　　（1）域名解析

　　（2）建立TCP连接，三次握手

　　（3）Web浏览器向Web服务端发送HTTP请求报文

　　（4）服务器响应HTTP请求

　　（5）浏览器解析HTML代码，并请求HTML代码中的资源（JS，CSS，图片）（这是自动向服务器请求下载的）

　　（6）浏览器对页面进行渲染呈现给客户

　　（7）断开TCP连接



![img](../Pic/20170516223533953.png)

---

如何解析对应的IP地址？域名解析过程（注意了先走本地再走DNS）

![img](../Pic/20170516223543890.png)



## TCP 报文

![image-20220830195115429](../Pic/image-20220830195115429.png)

* 源端口
* 目的端口
  * 源端口 + 目的端口 + 源 IP + 目的 IP 唯一确定一条 TCP 连接
  * Socket 的四元素
* 序号
  * 是TCP 可靠传输的关键部分。
  * 序号是该报文段发送的数据组的第一个字节的序号
  * 在TCP 传送的流中，每一个字节都有一个序号。
* 确认号
  * 指明下一个期待收到的字节序号，表明该序号之前的所有数据都已经准确无误的收到。
  * 确认号只有当 ACK 为 1 的时候才有效
* 首部长度/数据偏移
  * 指出 TCP 报文的数据距离 TCP 报文段的起始处有多远
* 保留位 6位
* 控制位
  * 紧急URG：当URG=1，表明紧急指针字段有效。告诉系统此报文段中有紧急数据
  * 确认ACK：仅当ACK=1时，确认号字段才有效。TCP规定，在连接建立后所有报文的传输都必须把ACK置1。
  * 推送PSH：当两个应用进程进行交互式通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应，这时候就将PSH=1。
  * 复位RST：当RST=1，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立连接。
  * 同步SYN：在连接建立时用来同步序号。当SYN=1，ACK=0，表明是连接请求报文，若同意连接，则响应报文中应该使SYN=1，ACK=1。
  * 终止FIN：用来释放连接。当FIN=1，表明此报文的发送方的数据已经发送完毕，并且要求释放。
* 窗口
  * 滑动窗口大小，用来告知发送端，接收端缓存的大小，以此控制发送端发送数据的速率
* 校验和
* 紧急指针
* 选项和填充
* 数据部分



## TCP 如何保证传输可靠性

* **基于数据块的传输**
  * 应用数据被切割为适合发送的数据块，再传送给网络层发送

* **超时重传**
  * 当发送方发送数据之后，启动一个定时器，等待目的端确认收到
  * 如果发送端在一定时间内没有收到目的端的确认，对应数据包假定为已丢失并进行重传
* **序列号**
  * TCP 为了保证不发生丢包，就给每个包一个序列号
  * 有了序列号能够将接受到的数据包排序，并且去掉重复序列号的数据包进行去重
* **校验和**
  * TCP 将保持它首部和数据的检验和
  * 这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化
  * 如果检验和有差错，TCP 将丢弃这个报文段
* **流量控制**
  * TCP 连接的每一方都有固定大小的缓冲空间
  * TCP 的接受端只允许发送端发送自己缓冲区能够接纳的数据。
  * 当接收方来不及处理发送方的数据，会提示发送方降低发送的速率
  * TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）
* **拥塞控制**
  * 当网络拥塞，减少数据的发送



## TCP 流量控制

> TCP 利用滑动窗口来实现流量控制
>
> 目的是，为了控制发送方的速率，保证接收方来得及接收
>
> 接收方发送的确认报文中，窗口字段，可以用来控制发送方窗口大小，从而影响发送方的速率



为什么需要流量控制？

双方在通信的时候，发送方和接收方的速率不一定相等。虽然有缓冲区的存在，但是假如接受方缓冲区满，发送方发送的数据就会被丢弃



TCP 发送窗口

![image-20220830204526244](../Pic/image-20220830204526244.png)

**可用窗口大小** = `SND.UNA + SND.WND - SND.NXT` 。

---

TCP 接收窗口

![image-20220830204549779](../Pic/image-20220830204549779.png)



## TCP 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的部分，网络的性能就要变坏。

网络中的数据太多，导致某个路由器处理不过来或处理地太慢，这就是**网络拥塞**。

拥塞控制就是为了**防止过多的数据注入到网络中**

拥塞控制是一个**全局性的过程**，<u>涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素</u>。

相反，<u>流量控制往往是点对点通信量的控制，是个端到端的问题。</u>流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

> TCP 的拥塞控制采用了四种算法：
>
> 慢开始、拥塞避免、快重传和快恢复

![img](../Pic/SouthEast.jpeg)



### 慢开始

**首先使用一个小的发送窗口，之后指数增大**

慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍

### 拥塞避免

**发送窗口指数增大变为线性增大**

拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.

### 快重传、快恢复

 **快重传要求接收方在收到一个失序的报文段后就立即发出重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，**而不必继续等待设置的重传计时器时间到期。**

快重传配合使用的还有**快恢复算法**，有以下两个要点:

①当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。

②考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。

![image-20220830205807300](../Pic/image-20220830205807300.png)

## 三次握手、四次挥手

一定一定要明白

socket 有两种



一种是服务端监听的 socket

能得到什么？ 得到客户端建立的连接

怎么得到的： socket client = server.accept()

会维护一个队列：accept 队列 backlog（内核配置，程序接口配置） 控制大小



一种是连接的 socket(1,服务端accept(), 2,客户端 connect())

得到什么？得到数据，发送数据

recv-buf

send-buf





![image-20220814093820741](https://s2.loli.net/2022/08/14/8GABCRYky7NjUH5.png)



* netstat -natp
* ss -lna



问题： LISTEN 状态的服务器， listen socket 的接受、发送队列放什么    

问题： Connection refused

内核先建立连接，连接是否被程序拿来使用

listen 的 accept 队列，等待程序接受的连接，大小是有限制的 

backlog  不被程序取走，允许堆多少

**backlog  满了 accept 满了，新来的客户端 直接 Connection refuse**d

> 三次握手，四次挥手，在回答的时候一定要和程序挂钩，解释状态什么时候出现，会出现什么问题，怎么排查

三次握手，内核层次的过程，建立连接后，socket 放入 accept 队列，等待程序调用

![image-20220814095525119](https://s2.loli.net/2022/08/14/z6WMSlqpH47BkGU.png)



四次挥手

![image-20220814101110824](https://s2.loli.net/2022/08/14/rc4Mb9JTWg3KZYs.png)





![image-20220814101740080](https://s2.loli.net/2022/08/14/DTnA27k4PfGqiMF.png)



### 为什么客户端最后还要等待2MSL？

MSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。

* 第一，**保证客户端发送的最后一个ACK报文能够到达服务器**，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
* 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，**在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。**这样新的连接中不会出现旧连接的请求报文。



### 为什么建立连接是三次握手，关闭连接确是四次挥手

* **建立连接的时候， 服务器在LISTEN状态下，已经准备好建立连接了**，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
* 而**关闭连接时**，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己未必全部数据都发送给对方了。（**自己未必准备好**）
* 所以**己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示现在才同意关闭连接**，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。



https://juejin.cn/post/6844903832435032072

## 长连接和短连接



长连接和短连接

TCP 只是连接，受应用层协议控制

本质区别是，这个连接是不是一个**复用载体**（不是在时间维度计算，是在复用维度计算）

举一个例子， http 1.0, 1.1 没有开启 keepalive 保持，连接只负责一次同步阻塞的请求 + 响应，短连接

举一个例子， http 1.0, 1.1 开启了 keepalive 保持，同步复用连接，可以多次请求 + 响应，无状态通信

举一个例子，dubbo 协议(rpc)，打开连接，同步/异步复用连接：多次（请求+响应）（请求请求）（响应响应），当复用连接的时候，需要消息的 ID，而且客户端和服务端同时完成这个约束，有状态通信



## IO 模型

0： IO 是程序对着内核 socket-queue 的包装

BIO： 读取，一直等 queue 里有才返回，阻塞，一个连接对应一个线程

NIO：读取，立刻返回：两种结果，读到，没读到，程序逻辑自己维护

多路复用器：内核增加 select，poll，epoll 新增的和数据接受，连接接受实质无关的调用，得到的是 socket 的事件，可以有效地再次 acept，R/W同步阻塞，同步非阻塞

BIO，NIO，多路复用器，在 IO 模型上都是同步的，都是程序自己 accept，R/W







## 分包，粘包，拆包

有程序，有内核，程序和内核协调工作

有一些是内核做的事情，三次握手，数据发送出去，接受进来，内核 TCP

到我们自己的程序，即便在一个 socket 里，也可能收到多个消息在一个字节数组中，我们要自己拆解



## 下一跳

下一跳：每个互联网设备内存不需要存全网数据，只需要存它周边一步内的数据 

arp 是一个协议，**解释 ip 地址和网卡硬件地址（MAC）的映射**，受限于同一局域网

链路层重新封装下一跳的 MAC 地址，去下一跳

TCP/IP 协议基于下一跳机制：

* ip 地址定义端点之间
* mac 地址是结点间的



## arp 协议学习

arp 目标 MAC 地址全 F，目标IP，192.168.1.1

交换机，如果看到目标 MAC 地址全 F，这个数据包会被广播出去

---

ARP 协议，全称 **地址解析协议（Address Resolution Protocol）**，

它解决的是**网络层地址和链路层地址之间的转换问题**。

因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 <u>IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题</u>。



### 同一局域网内的 MAC 寻址

![img](../Pic/arp_same_lan.008bdaef.png)

**广播问询，单播响应**

1. 主机 A 想要给主机 B 发送 IP 数据报，如果主机 B 的 IP-MAC 映射信息已经存在于主机 A 的 ARP 表中，那么主机 A 无需广播，只需提取 MAC 地址并构造链路层帧发送即可。
2. ARP 表中的映射信息是有生存周期的，典型值为 20 分钟。
3. 目标主机接收到了问询主机构造的问询报文后，将先把问询主机的 IP-MAC 映射存进自己的 ARP 表中，这样才能获取到响应的目标 MAC 地址，顺利的发送响应分组。

### 不同局域网内的 MAC 寻址

路由器作为互联设备，具有多个接口，每个接口同样也应该具备不重复的 IP 地址和 MAC 地址。因此，在讨论 ARP 表时，路由器的多个接口都个各自维护一个 ARP 表，而非一个路由器只维护一个 ARP 表。

接下来，回顾同一子网内的 MAC 寻址，如果主机 A 发送一个广播问询分组，那么 A 所在子网内的所有设备（接口）都将不会捕获该分组，因为该分组的目的 IP 地址在另一个子网中，本子网内不会有设备成功接收。那么，主机 A 应该发送**查询分组**

路由器目标接口接收到了主机 A 发过来的链路层帧，解析，根据目的 IP 地址，查询转发表，将该 IP 数据报**转发**到与主机 B 所在子网相连的接口上。

![img](../Pic/arp_different_lan.ad156523.png)

## Tomcat 为什么慢？

* Tomcat 本身处在应用层，第七层，需要下面的层数都运行完才传到最上层
* Tomcat 是 Java 语言实现的，在内核的基础上又引入了 虚拟机



## 负载均衡

注意，负载均衡服务器特别的快，转发级别，不会和 client 握手。

**后端服务器是镜像的，长得一摸一样的**

![image-20220814143028267](https://s2.loli.net/2022/08/14/HuEW7lhNIFadRQv.png)

D-NAT

* 非对称，带宽成为瓶颈
* 消耗算力



![image-20220814150404912](https://s2.loli.net/2022/08/14/YsuiURP4HrhlKyW.png)



DR：

* 基于 2 层
* MAC 地址欺骗
* 速度快，成本低

![image-20220814151753704](https://s2.loli.net/2022/08/14/VifM8qh5yZBNgzR.png)









